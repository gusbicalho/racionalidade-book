<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <link href='https://fonts.googleapis.com/css?family=Merriweather:400,700,700italic,400italic|Merriweather+Sans&subset=latin,latin-ext' rel='stylesheet' type='text/css'>
  <link rel='stylesheet' href='style.css' type='text/css'>
  <script
    src="https://code.jquery.com/jquery-3.1.1.slim.min.js"
    integrity="sha256-/SIrNqv8h6QGKDuNoLGA4iret+kyesCkHGzVUUV0shc="
    crossorigin="anonymous"></script>
  <script type="text/javascript" src="index.js"></script>
  <title>Racionalidade - De AI a Zumbis</title>
</head>

<body>

<img class="cover" src="images/cover.jpg">

<section class="inside-cover">
  <h1>Racionalidade<br>De AI a Zumbis</h1>
  <h2>Eliezer Yudkowsky</h2>
  <img src="images/miri-logo.png">
</section>

<section class="cover-sheet">
  <p>Eliezer Yudkowsky é Pesquisador no Machine Intelligence Research Institute <br>
     (Instituto de Pesquisa de Inteligência de Máquina).</p>
  <p>Escrito por Eliezer Yudkowsky.</p>
  <p>Publicado em 2015<br>
     Machine Intelligence Research Institute<br>
     Berkeley 94704<br>
     Estados Unidos da América<br>
     <a target="_blank" href="http://intelligence.org">intelligence.org</a></p>
  <p>Disponibilizado sob os termos da licença Creative Commons Atribuição-Uso Não Comercial-Compartilhamento pela mesma licença 3.0 (não adaptada).<br>
     <a target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/3.0/deed.pt_BR">CC BY-NC-SA 3.0</a></p>
  <p>ISBN-10: 1-939311-15-2<br>
     ISBN-13: 978-1-939311-15-3 (epub)</p>
  <p>O Machine Intelligence Research Institute agradece ao generoso apoio de todos os envolvidos na publicação deste livro, e aos doadores que financiam o trabalho do MIRI em geral.</p>
  <p>Capa feita por Tim Woolley.</p>
  <p>* * *</p>
  <p>Tradução para o português:<p>
  <table>
    <tr><td>Gustavo Bicalho (coord.)</td>
        <td>Silziane Carvalho (coord.)</td></tr>
    <tr><td>Anderson L. R. Calixto</td>
        <td>Arthur Helfstein Fragoso</td></tr>
    <tr><td>Fabiane Pohlmann</td>
        <td>Graciela Kunrath Lima</td></tr>
    <tr><td>Israel Meneses Santos Vilas Bôas</td>
        <td>Leo H. M. Arruda</td></tr>
  </table>
  <p>Acompanhe a tradução em<br>
     <a target="_blank" href="http://racionalidade.com.br/wiki">http://racionalidade.com.br/wiki</a><br>
     <a target="_blank" href="https://www.facebook.com/groups/452897608198563/">https://www.facebook.com/groups/452897608198563/</a>


</section>

<nav id="toc">
  <h1>Sumário</h1>
  <ul>
    <li><a href="#toc">Sumário</a></li>
    <li><a href="#art-pref">Prefácio</a></li>
    <li><a href="#art-intro">Vieses: Uma introdução</a></li>
    <li><a href="#book-i">Livro I - Mapa e Território</a>
      <ul>
        <li><a href="#seq-a">A. Previsivelmente Errado</a>
          <ul>
            <li><a href="#art-1">1. O que quero dizer com “racionalidade”?</a></li>
            <li><a href="#art-2">2. Sentindo-se racional</a></li>
            <li><a href="#art-3">3. Por que a verdade? E...</a></li>
            <li><a href="#art-4">4. ...O que é um viés, mesmo?</a></li>
            <li><a href="#art-5">5. Disponibilidade</a></li>
            <li><a href="#art-6">6. Detalhes onerosos</a></li>
            <li><a href="#art-7">7. Falácia do planejamento</a></li>
            <li><a href="#art-8">8. Ilusão de transparência: por que ninguém entende você</a></li>
            <li><a href="#art-9">9. Esperando distâncias inferenciais curtas</a></li>
            <li><a href="#art-10">10. A lente que vê suas próprias falhas</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>

<section><!-- Intro -->

  <article id="art-pref"><h1>Prefácio</h1>

    <p>Você tem em suas mãos uma compilação de dois anos de posts diários de um blog. Em retrospecto, eu olho para esse projeto e vejo um número enorme de coisas que eu fiz completamente errado. Eu estou bem com isso. Olhar para trás e <em>não</em> ver um monte de coisas que eu fiz de errado significaria que nem a minha escrita, nem o meu entendimento teriam melhorado desde 2009. <em>Ops</em> é o som que fazemos quando melhoramos nossas crenças e estratégias; assim, olhar para trás e não ver qualquer coisa que você fez de errado significa que você não aprendeu nada nem mudou sua mente desde então.</p>
    <p>Foi um erro não ter escrito os meus dois anos de posts com a intenção de ajudar as pessoas a se darem melhor em suas vidas cotidianas. Eu escrevi com a intenção de ajudar as pessoas a resolver problemas grandes, difíceis, importantes, e escolhi problemas abstratos, que soavam impressionantes, como meus exemplos.</p>
    <p>Em retrospecto, esse foi o segundo maior erro na minha abordagem. Ele está ligado ao <em>primeiro</em> maior erro nos meus escritos, que foi não entender que o grande problema para aprender essa valiosa forma de pensar era descobrir como praticar, não conhecer a teoria. Eu não percebi que essa parte tinha prioridade; e sobre isso eu só posso dizer “Ops” e “Duh”.</p>
    <p>Sim, às vezes essas grandes questões realmente são grandes e realmente são importantes; mas isso não muda a verdade básica de que para dominar as habilidades, você precisa praticá-las, e é mais difícil praticar usando coisas que estão mais distantes (hoje, o <em>Center for Applied Rationality (Centro para Racionalidade Aplicada)</em> está trabalhando para reparar esse meu enorme erro de uma forma mais sistemática.)</p>
    <p>Um terceiro grande erro que eu cometi foi me concentrar demais na crença racional, e muito pouco na ação racional.</p>
    <p>O quarto maior erro que cometi foi que eu deveria ter organizado melhor o conteúdo que eu estava apresentando nas sequências. Em particular, eu deveria ter criado um wiki muito antes, e tornado mais fácil ler os posts em sequência.</p>
    <p><em>Esse</em> erro, pelo menos, é corrigível. No presente trabalho, Rob Bensinger reordenou os posts e os reorganizou tanto quanto possível, sem tentar reescrever todo o material (embora ele tenha reescrito um pouco dele).</p>
    <p>Meu quinto grande erro foi que eu – na forma como eu via – tentei falar francamente sobre a estupidez do que me pareciam ser ideias estúpidas. Eu tentei, sim, evitar a falácia conhecida como Bulverismo, em que você <em>começa</em> a discussão falando sobre o quão estúpidas as pessoas são por acreditar em algo; eu sempre discuti a questão em primeiro lugar, para só depois dizer: “E, portanto, isso é estúpido”. Mas, em 2009, não estava claro para mim se não seria importante atrair algumas pessoas que expressassem desprezo pela homeopatia. Eu achava, e ainda acho, que existe um lamentável problema de que tratar ideias com cortesia leva muitas pessoas a acreditar, em algum nível, que “Nada de ruim vai acontecer comigo se eu disser que acredito isso; eu não vou perder status se eu disser que acredito em homeopatia”, e que o riso de escárnio dos comediantes pode ajudar as pessoas a despertar do sonho.</p>
    <p>Hoje eu escreveria de forma mais cortês, eu acho. A falta de cortesia serviu, sim, a uma função, e eu acho que ajudou algumas pessoas; mas agora eu levo mais a sério o risco de construir comunidades onde a reação normal e esperada a opiniões diferentes tidas como de baixo status é a zombaria e o desprezo.</p>
    <p>Apesar do meu erro, eu fico feliz em dizer que meus leitores têm sido, até agora, surpreendentemente bons em <em>não</em> usar minha retórica como desculpa para intimidar ou menosprezar os outros (quero destacar Scott Alexander aqui em particular, que é uma pessoa mais gentil do que eu e um escritor cada vez mais sensacional sobre estes temas, e talvez mereça parte do crédito por criar uma cultura saudável no <em>Less Wrong</em>).</p>
    <p>Ser capaz de olhar para trás e dizer que você “falhou” significa que você tinha objetivos. Então, o que era que eu estava tentando fazer?</p>
    <p>Há uma certa maneira valiosa de pensar, que ainda não é ensinada nas escolas, nos dias de hoje. Essa certa maneira de pensar não é, de modo algum, ensinada de forma sistemática. Ela só é absorvida por pessoas que cresceram lendo livros como <em>Surely You’re Joking, Mr. Feynman (O senhor está brincando, Sr. Feynman!)</em> ou que têm um professor especialmente bom na escola.</p>
    <p>Reconhecidamente, essa certa maneira de pensar tem a ver com ciência, e com o método experimental. A parte da ciência onde você sai e olha para o universo em vez de apenas inventar ideias. A parte em que você diz “Ops” e desiste de uma teoria ruim quando os experimentos não a sustentam.</p>
    <p>Mas essa certa maneira de pensar vai além disso. É mais profunda e mais universal do que um par de óculos que você coloca quando você entra em um laboratório e tira quando você sai. Ela se aplica à vida diária, embora essa parte seja mais sutil e mais difícil. Mas se você não conseguir dizer “Ops” e desistir quando parece que algo não está funcionando, você não vai ter escolha a não ser continuar atirando no próprio pé. Você vai ter que continuar recarregando a arma e você vai ter que continuar puxando o gatilho. Você conhece pessoas assim. E em algum lugar, em algum ponto da sua vida em que você prefere não pensar, você <em>é</em> uma pessoa assim. Seria bom se houvesse um certo modo de pensar que nos ajudasse a parar de fazer isso.</p>
    <p>Apesar do tamanho dos meus erros, esses dois anos de posts parecem ter ajudado um número surpreendente de pessoas em um grau surpreendente. Não funcionou de forma confiável, mas funcionou algumas vezes.</p>
    <p>Na sociedade moderna, tão pouco é ensinado das habilidades de crença racional e tomada de decisão, tão pouco da matemática e das ciências que lhes são subjacentes... que acontece que a simples leitura de um enorme “despejo cerebral”<em>[“brain-dump”, no original]</em> cheio de problemas em filosofia e ciência pode, sim, ser surpreendentemente bom para você. Passar por tudo isso, a partir de uma dúzia de ângulos diferentes pode, às vezes, transmitir uma ideia do ritmo central.</p>
    <p>Porque tudo, no fim das contas, é uma coisa só. Eu falei sobre grandes e importantes problemas distantes e deixei de lado a vida cotidiana, mas as leis que os regem não são realmente diferentes. Há grandes lacunas nas partes em que me foquei, e eu escolhi todos os exemplos errados; mas, no fim das contas, tudo é uma coisa só. Tenho orgulho de olhar para trás e dizer isto, mesmo depois de todos os erros que cometi, e todas as outras vezes que eu disse “Ops”...</p>
    <p>Mesmo cinco anos depois, ainda me parece que isso é melhor do que nada.</p>

    <p style="text-align:right">– Eliezer Yudkowsky, fevereiro de 2015</p>

  </article>

  <article id="art-intro"><hgroup><h1>Vieses: Uma introdução</h1>
                                  <p class="subtitle">por Rob Bensinger</p>
                          </hgroup>

    <p>Não é segredo. Por alguma razão, no entanto, raramente surge nas conversas, e poucas pessoas estão perguntando o que devemos fazer sobre isso. É um padrão, escondido invisível por trás de todos os nossos triunfos e fracassos, invisível por trás dos nossos olhos. O que é?</p>
    <p>Imagine colocar seu braço em uma urna que contém setenta bolas brancas e trinta bolas vermelhas, e retirar dez bolas misteriosas. Talvez três das dez bolas sejam vermelhas, e você vai adivinhar corretamente quantas esferas vermelhas, no total, havia na urna. Ou talvez aconteça de você pegar quatro bolas vermelhas, ou algum outro número. Então você provavelmente vai errar o número total.</p>
    <p>Este erro aleatório é o preço do conhecimento incompleto, e, para um erro, até que não é tão ruim. <em>Na média</em>, suas estimativas não serão incorretas, e quanto mais você aprender, menor o seu erro tenderá a ser.</p>
    <p>Por outro lado, suponhamos que as bolas brancas fossem mais pesadas, e afundassem para o fundo de urna. Então a sua amostra poderia ser pouco representativa <em>em uma direção consistente</em>.</p>
    <p><em>Esse</em> tipo de erro é chamado de “viés estatístico”. Quando o seu método de aprendizagem do mundo é tendencioso, aprender mais pode não ajudar. Adquirir mais dados podem até mesmo <em>piorar</em> consistentemente uma previsão tendenciosa.</p>
    <p>Se você está acostumado a ter em alta estima o conhecimento e a investigação, esta é uma perspectiva assustadora. Se queremos ter certeza de que aprender mais vai nos ajudar, em vez de nos deixar pior do que estávamos antes, precisamos descobrir e corrigir os desvios em nossos dados.</p>
    <p>A ideia de <em>viés cognitivo</em> em psicologia funciona de forma análoga. Um viés cognitivo é um erro sistemático na <em>maneira como pensamos</em>, ao contrário de um erro aleatório ou um que é apenas causado por nossa ignorância. Enquanto um viés estatístico distorce uma amostra de modo que ela se aproxime menos estreitamente de uma população maior, vieses cognitivos distorcem nossas <em>crenças</em>, de modo que elas representam os fatos com menor precisão, e distorcem nossa <em>tomada de decisão</em>, fazendo com que ela seja menos confiável para alcançar nossos objetivos.</p>
    <p>Talvez você tenha um viés de otimismo, e descubra que as bolas vermelhas podem ser usadas para tratar uma doença tropical rara que aflige seu irmão. Então, você poderá superestimar o número de bolas vermelhas contidas na urna porque você <em>deseja</em> que a maioria das bolas fossem vermelhas. Aqui, não é a sua amostra que é enviesada. <em>Você</em> é que é enviesado.</p>
    <p>Agora que estamos falando de <em>pessoas</em> enviesadas, no entanto, temos de ter cuidado. Normalmente, quando nós chamamos indivíduos ou grupos de “tendenciosos” ou “enviesados”, nós fazemos isso para repreendê-los por serem injustos ou parciais. Um viés <em>cognitivo</em> é um bicho completamente diferente. Vieses cognitivos são uma parte fundamental de como os seres humanos pensam em geral, não o tipo de defeito que decorre de uma educação péssima ou uma personalidade ruim.<ref>1</ref></p>
    <p>Um viés cognitivo é uma forma sistemática pela qual seus padrões inatos do pensamento ficam aquém da verdade (ou de algum outro objetivo atingível, como a felicidade). Como os vieses estatísticos, os vieses cognitivos podem distorcer nossa visão da realidade, nem sempre podem ser consertados simplesmente recolhendo mais dados, e seus efeitos podem se acumular com o tempo. Mas quando o instrumento de medição descalibrado que você está tentando consertar é <em>você</em>, eliminar o viés é um desafio único.</p>
    <p>Ainda assim, esse é um lugar óbvio para começar. Porque, se você não pode confiar em seu cérebro, como você pode confiar em qualquer outra coisa?</p>
    <p>Seria útil ter um nome para este projeto de superação de vieses cognitivos, e de superação de todas as espécies de erro pelas quais nossas mentes possam vir a prejudicar a si mesmas.</p>
    <p>Poderíamos chamar esse projeto de qualquer coisa que quiséssemos. Por ora, porém, eu acredito que “racionalidade” é um nome tão bom quanto qualquer outro.</p>

    <h2>Sentimentos racionais</h2>

    <p>Nos filmes de Hollywood, ser “racional” normalmente significa que você é um estoico severo e hiperintelectual. Pense no Spock de <em>Star Trek</em>, que “racionalmente” suprime suas emoções, “racionalmente” se recusa a confiar em intuições ou impulsos, e é facilmente confundido e passado para trás ao encontrar um oponente errático ou “irracional”.<ref>2</ref></p>
    <p>Há uma noção completamente diferente de “racionalidade”, estudada por matemáticos, psicólogos e cientistas sociais. A grosso modo, é a ideia de <em>fazer o melhor que pode com o que você tem</em>. Uma pessoa racional, não importa o quão desnorteada e perdida esteja, forma as melhores crenças possíveis com as evidências que têm. Uma pessoa racional, não importa o quão terrível a situação em que ela esteja, faz as melhores escolhas que pode para melhorar suas chances de sucesso.</p>
    <p>Racionalidade do mundo real não se trata de ignorar suas emoções e intuições. Para um ser humano, a racionalidade muitas vezes significa tornar-se mais autoconsciente sobre seus sentimentos, para que possa levá-los em conta em suas decisões.</p>
    <p>A racionalidade pode até significar saber quando <em>não</em> pensar demais. Ao escolher um cartaz para colocar em sua parede, ou ao prever o resultado de um jogo de basquete, observou-se que participantes de experimentos se davam <em>pior</em> caso analisassem cuidadosamente as suas razões.<ref>3</ref><ref>4</ref> Existem alguns problemas onde a deliberação consciente nos serve melhor, e outros em que julgamentos instantâneos nos servem melhor.</p>
    <p>Os psicólogos que trabalham em teorias de duplo processo traçam uma distinção entre os processos cerebrais do “Sistema 1” (cognição rápida, implícita, associativa, automática) e os do “Sistema 2” (cognição lenta, explícita, intelectual, controlada).<ref>5</ref> O <em>estereótipo</em> é que racionalistas confiam inteiramente no Sistema 2, desconsiderando seus sentimentos e impulsos. Olhando para além do estereótipo, alguém que estivesse sendo realmente racional – realmente alcançando seus objetivos, realmente mitigando os danos de seus vieses cognitivos – dependeria fortemente dos hábitos e intuições do Sistema 1, nos casos em que eles fossem confiáveis.</p>
    <p>Infelizmente, o Sistema 1 sozinho parece ser um guia <em>terrível</em> para decidir “quando devo confiar no Sistema 1?” Nossas intuições destreinadas não nos avisam quando devemos parar de confiar nelas. O <em>sentimento</em> é o <em>mesmo</em>, estando você enviesado ou não.<ref>6</ref></p>
    <p>Por outro lado, como observa o economista comportamental Dan Ariely: somos <em>previsivelmente</em> irracionais. Nós fazemos besteiras sempre das mesmas formas, repetida e sistematicamente.</p>
    <p>Embora não possamos usar nossa intuição para descobrir quando estamos sucumbindo a um viés cognitivo, talvez sejamos capazes de usar as ciências da mente.</p>

    <h2>As Muitas Faces do Viés</h2>

    <p>Para resolver problemas, nossos cérebros evoluíram para empregar heurísticas cognitivas – atalhos rudimentares que obtêm a resposta certa frequentemente, mas nem sempre. Vieses cognitivos surgem quando as aproximações feitas por estas heurísticas produzem um erro relativamente consistente e bem delimitado.</p>
    <p>A heurística da representatividade, por exemplo, é a nossa tendência de avaliar fenômenos segundo o quão representativos de várias categorias eles são. Isso pode levar a vieses, como a <em>falácia da conjunção</em>. Tversky e Kahneman descobriram que participantes de um experimento consideravam menos provável que um tenista habilidoso iria “perder o primeiro set” do que que ele iria “perder o primeiro set, mas ganhar o jogo”.<ref>7</ref> Ganhar de virada parece mais <em>típico</em> de um jogador habilidoso, por isso superestimamos a probabilidade dessa narrativa complicada-mas-que-soa-razoável, em comparação com a probabilidade de um cenário estritamente mais simples.</p>
    <p>A heurística da representatividade também pode contribuir para a <em>negligência da taxa-base</em>, em que baseamos nossas decisões em quão intuitivamente “normal” uma combinação de atributos é, negligenciando o quão comum cada atributo é na população em geral.<ref>8</ref> É mais provável que Steve seja um bibliotecário tímido, ou que ele seja um vendedor tímido? A maioria das pessoas respondem a esse tipo de pergunta pensando sobre se “tímido” corresponde a seus estereótipos dessas profissões. Eles não levam em consideração o quão mais comuns os vendedores são que os bibliotecários &mdash; setenta e cinco vezes mais comuns, nos Estados Unidos<ref>9</ref>.</p>
    <p>Outros exemplos de vieses incluem a <em>negligência da duração </em>(avaliar experiências sem levar em conta o tempo que elas duraram), a <em>falácia do custo irrecuperável</em> (sentir-se comprometidos com coisas nas quais você despendeu recursos no passado, quando você deveria limitar suas perdas e seguir em frente), e o <em>viés de confirmação</em> (dar mais peso às evidências que confirmam o que já acreditamos)<ref>10</ref><ref>11</ref>.</p>
    <p>Saber sobre um viés, no entanto, raramente é suficiente para protegê-lo dele. Em um estudo sobre a <em>cegueira a vieses</em>, sujeitos experimentais previram que, se eles soubessem que uma pintura era o trabalho de um artista famoso, eles teriam mais dificuldade para avaliar, de forma neutra, a qualidade da pintura. E, de fato, os indivíduos que foram informados o autor de uma pintura e solicitados a avaliar a sua qualidade exibiram o exato viés que eles mesmos haviam previsto, em comparação com um grupo de controle. Quando perguntados <em>depois</em>, no entanto, os mesmos indivíduos afirmaram que suas avaliações das pinturas tinham sido objetivas e não afetadas pelo viés – em todos os grupos!<ref>12</ref><ref>13</ref></p>
    <p>Temos uma aversão especial a pensar que nossos pontos de vista são imprecisos em comparação com os pontos de vista dos outros. Mesmo quando identificamos corretamente os vieses dos outros, temos um <em>ponto cego para vieses</em> especial quando se trata de nossas próprias falhas.<ref>14</ref> Nós não conseguimos detectar quaisquer “pensamentos que parecem enviesados” quando refletimos internamente, e, assim, concluímos que somos simplesmente mais objetivos do que todos as outras pessoas<ref>15</ref>.</p>
    <p>Estudar vieses pode, na verdade, torná-lo <em>mais</em> vulnerável ao excesso de confiança e ao viés de confirmação, quando você começa a ver a influência dos vieses cognitivos em todos ao seu redor – em todos, exceto em si mesmo. E o ponto cego, ao contrário de muitos vieses, é <em>especialmente grave</em> entre as pessoas que são <em>especialmente inteligentes, atenciosas, e de mente aberta</em> <ref>16</ref><ref>17</ref>.</p>
    <p>Isso é motivo de preocupação.</p>
    <p>Ainda assim... parece que devemos ser capazes de melhorar. Sabe-se que podemos reduzir a negligência da taxa-base ao pensar em probabilidades como frequências de objetos ou eventos. Podemos minimizar a negligência da duração, direcionando mais atenção à duração e representando-a graficamente<ref>18</ref>. As pessoas variam em quão fortemente exibem diferentes vieses, portanto deve haver uma série de formas ainda desconhecidas de influenciar o quão enviesados nós somos.</p>
    <p>Se quisermos melhorar, no entanto, não é suficiente nos debruçarmos sobre as listas de vieses cognitivos. A abordagem para superar vieses em <em>Racionalidade: De AI a Zumbis</em> é comunicar uma compreensão sistemática de por que o raciocínio correto funciona, e de como o cérebro fica aquém dele. Na medida em que este livro alcança esse objetivo, a sua abordagem pode ser comparada com o descrito por Serfas, que nota que “anos de experiência de trabalho envolvendo finanças” não afetaram a suscetibilidade das pessoas ao viés do custo irrecuperável, ao passo que “o número cursos de contabilidade frequentados” ajudava.</p>
    <blockquote>Como consequência, pode ser necessário distinguir entre experiência e perícia, perícia significando “o desenvolvimento de um princípio esquemático que envolve a compreensão conceitual do problema”, a qual, por sua vez, permite que o tomador de decisão reconheça determinados vieses. No entanto, usar a perícia como contramedida exige mais do que apenas estar familiarizado com o conteúdo da situação ou ser um especialista em um domínio específico. Exige que a pessoa entenda completamente a lógica subjacente do respectivo viés, seja capaz de detectá-lo no ambiente específico, e também que tenha à mão as ferramentas adequadas para combater o viés<ref>19</ref>.</blockquote>
    <p>O objetivo deste livro é o de estabelecer as bases para a criação de uma “perícia” da racionalidade. Isso significa adquirir uma compreensão profunda da estrutura de um problema muito geral: o viés humano, o autoengano, e os mil caminhos pelos quais o pensamento sofisticado pode derrotar a si mesmo.</p>

    <h2>Uma palavra sobre este texto</h2>

    <p><em>Racionalidade: De AI a Zumbis</em> começou sua vida como uma série de ensaios de Eliezer Yudkowsky, publicados entre 2006 e 2009 no blog de economia <em>Overcoming Bias [Superando o Viés]</em> e no blog comunitário dele derivado <em>Less Wrong</em>. Eu trabalhei com Yudkowsky durante o ano passado no Machine Intelligence Research Institute (MIRI), uma organização sem fins lucrativos fundada por ele em 2000 para estudar os requisitos teóricos para uma inteligência artificial (IA <em>[ou AI, na sigla em inglês]</em>) mais inteligente do que a humana.</p>
    <p>Ler seus posts no blog fez com que me interessasse pelo seu trabalho. Ele me impressionou com sua capacidade de comunicar de forma concisa compreensões que eu levara anos de estudo de filosofia analítica para internalizar. Na tentativa de reconciliar o espírito anárquico e cético da ciência com uma abordagem rigorosa e sistemática à indagação, Yudkowsky tenta não apenas refutar, mas <em>entender</em> os muitos passos em falso e becos sem saída que a má filosofia (e a má falta-de-filosofia) pode produzir. Ao ajudar a organizar estes ensaios em um livro, minha esperança é tornar mais fácil mergulhar neles, e mais fácil apreciá-los como um todo coerente.</p>
    <p>O manual de racionalidade resultante é frequentemente pessoal e irreverente, tendo como pontos de partida, por exemplo, as experiências de Yudkowsky com sua mãe (uma psiquiatra) e pai (um físico) judeus ortodoxos e conversas em salas de chat e listas de discussão. Os leitores que conhecem Yudkowsky de <em>Harry Potter e os Métodos da Racionalidade</em>, sua abordagem cientificamente orientada da série <em>Harry Potter</em>, de J.K. Rowling, vão reconhecer a mesma iconoclastia irreverente, e muitos dos mesmos conceitos fundamentais.</p>
    <p>Estilisticamente, os ensaios deste livro percorrem toda a gama de “livro didático divertido” a “compêndio de vinhetas inteligentes” a “manifesto rebelde”, e o conteúdo é correspondentemente variado. <em>Racionalidade: De AI a Zumbis</em> congrega centenas de posts de Yudkowsky em vinte e seis “sequências”, séries de posts ligados tematicamente, que funcionam como capítulos. As sequências, por sua vez, são agrupadas em seis livros, abrangendo os seguintes tópicos:</p>
    <p>Livro 1 – <strong>Mapa e território</strong>. O que é uma crença, e que faz com que algumas crenças funcionem melhor do que os outras? Essas quatro sequências explicam as noções <em>Bayesianas</em> de racionalidade, crença e evidência. Um tema comum: as coisas que chamamos de “explicações” ou “teorias” podem nem sempre funcionar como <em>mapas</em> de navegação do mundo. Como resultado, corremos o risco de misturar nossos mapas mentais com os outros objetos em nossa caixa de ferramentas.</p>
    <p>Livro 2 – <strong>Como alterar sua mente de verdade</strong>. Essa tal de verdade parece bastante útil. Por que, então, nós insistimos em tirar conclusões precipitadas, fincar nossos pés, e recapitular os mesmos erros? Por que somos tão <em>ruins</em> em adquirir crenças precisas, e como podemos ser melhores? Estas sete sequências discutem raciocínio motivado e viés de confirmação, com um foco especial em espécies de autoengano difíceis de reconhecer e na armadilha de “usar argumentos como soldados.”</p>
    <p>Livro 3 – <strong>A máquina no fantasma</strong>. Por que nós <em>não</em> evoluímos para ser mais racionais? Mesmo levando em conta as limitações de recursos, parece que poderíamos estar ganhando muito mais conhecimento com as evidências que temos disponíveis. Para obter uma imagem realista de como e porque nossas mentes executam as suas funções biológicas, precisamos abrir o capô e ver como funciona a evolução, e como nossos cérebros funcionam, com mais precisão. Estas três sequências esclarecem como até filósofos e cientistas podem errar quando confiam em noções intuitivas, não técnicas, sobre a evolução ou a psicologia. Ao localizar nossas mentes dentro de um espaço maior de sistemas guiados por objetivos, podemos identificar algumas das peculiaridades do raciocínio humano e compreender como tais sistemas podem “perder o seu propósito”.</p>
    <p>Livro 4 – <strong>Mera realidade</strong>. Em que tipo de mundo vivemos? Qual é o nosso lugar nesse mundo? Baseando-se nos exemplos das sequências anteriores de como modelos evolutivos e cognitivos funcionam, estas seis sequências exploram a natureza da mente e das leis da física. Além de aplicar e generalizar lições anteriores sobre mistérios científicos e parcimônia, esses ensaios levantam novas questões sobre o papel que a ciência deve desempenhar na racionalidade individual.</p>
    <p>Livro 5 – <strong>Mera bondade</strong>. O que torna algo <em>valioso</em> – moralmente, ou esteticamente, ou prudencialmente? Essas três sequências perguntam como podemos justificar, revisar, e naturalizar nossos valores e desejos. O objetivo é encontrar uma maneira de compreender os nossos objetivos sem comprometer os nossos esforços para realmente alcançá-los. Aqui, o maior desafio é saber quando confiar em seus confusos e complexos impulsos sobre o que é certo e errado caso a caso, e quando substituí-los por princípios simples e sem exceção.</p>
    <p>Livro 6 – <strong>Ficando mais forte</strong>. Como indivíduos e comunidades podem colocar tudo isso em prática? Estas três sequências começam com um relato autobiográfico dos maiores erros filosóficos do próprio Yudkowsky, com conselhos sobre como ele acha que os outros podem se sair melhor. O livro termina com recomendações para o desenvolvimento de currículos de racionalidade aplicada baseada em evidências, e para a formação de grupos e instituições para apoiar os estudantes interessados, educadores, pesquisadores e amigos.</p>
    <p>As sequências são complementadas com “interlúdios”, ensaios extraídos do site pessoal de Yudkowsky, <a target="_blank" href="http://www.yudkowsky.net/">http://www.yudkowsky.net</a>. Eles se ligam às sequências de várias maneiras; por exemplo, <em>As Doze Virtudes da Racionalidade</em> resume poeticamente muitas das lições de <em>Racionalidade: De AI a Zumbis</em>, e é frequentemente citado em outros ensaios.</p>
    <p>Clicar no asterisco ao final de um ensaio irá levá-lo à sua versão original no <em>Less Wrong</em> (onde você pode fazer comentários) ou no site de Yudkowsky. Você também pode consultar um glossário da terminologia de <em>Racionalidade: De AI a Zumbis</em> online, em <a target="_blank" href="http://wiki.lesswrong.com/wiki/RAZ_Glossary">http://wiki.lesswrong.com/wiki/RAZ_Glossary</a>.</p>

    <h2>Mapa e território</h2>

    <p>Este, o primeiro livro, começa com uma sequência sobre vieses cognitivos: “Previsivelmente errado”. O resto do livro não vai se ater apenas a este tema; maus hábitos e más ideias importam, mesmo quando eles surgem do conteúdo de nossas mentes, e não da estrutura. Assim, erros tanto evoluídos quanto inventados serão expostos nessas sequências, começando com uma discussão, em “Falsas Crenças”, sobre os modos como as expectativas de uma pessoa podem se desligar das crenças por ela professadas.</p>
    <p>Um relato da irracionalidade também estaria incompleto se não fornecesse qualquer teoria sobre como a <em>racionalidade</em> funciona, ou se a sua “teoria” consistisse apenas em obviedades vagas, sem nenhum mecanismo explicativo preciso. A sequência “Percebendo Confusão” investiga por que é útil basear seu comportamento em expectativas “racionais”, e qual é a sensação de se fazer isso.</p>
    <p>A seguir, “Respostas misteriosas” pergunta se a ciência resolve esses problemas por nós. Os cientistas baseiam seus modelos em experimentos reproduzíveis, não em especulações ou boatos. E a ciência tem um excelente histórico, comparada com anedotas, religião, e... basicamente todo o resto. Será que, mesmo assim, ainda precisamos nos preocupar com “falsas” crenças, viés de confirmação, viés de retrospectiva e similares, quando estamos trabalhando com uma comunidade de pessoas que buscam <em>explicar</em> fenômenos, e não apenas contar histórias atraentes?</p>
    <p>Esta sequência é seguida por <em>A Simples Verdade</em>, uma alegoria independente sobre a natureza do conhecimento e da crença.</p>
    <p>É o viés cognitivo, no entanto, que fornece a visão mais clara e direta sobre a matéria da nossa psicologia, na forma de nossas heurísticas e da lógica das nossas limitações. É com o viés que vamos começar.</p>
    <p>Há uma passagem no <em>Zhuangzi</em>, um texto filosófico proto-taoísta, que diz: “A armadilha para peixes existe por causa do peixe; uma vez que você tenha obtido o peixe, você pode esquecer a armadilha”.<ref>20</ref></p>
    <p>Eu convido você a explorar este livro com esse espírito. Use-o como você usaria uma armadilha para peixes, tendo sempre em mente o objetivo que você tem para ela. Leve com você o que puder usar, enquanto continuar sendo útil; descarte o resto. E que o seu propósito lhe sirva bem.</p>

    <h2>Agradecimentos</h2>

    <p>Eu sou estupendamente grato a Nate Soares, Elizabeth Tarleton, Paul Crowley, Brienne Strohl, Adam Freese, Helen Toner e dezenas de voluntários por revisar partes deste livro.</p>
    <p>Agradecimentos especiais e sinceros para Alex Vermeer, que dirigiu este livro até o fim, e Tsvi Benson-Tilsen, que vasculhou o livro inteiro para garantir a sua legibilidade e consistência.</p>

    <h2>Notas</h2>

    <notes>
      <note>A ideia de viés pessoal, viés da imprensa etc. se assemelha ao viés estatístico no fato de ser um <em>erro</em>. Outras formas de generalizar a ideia de “viés” se focam em sua associação com a não-aleatoriedade. No aprendizado de máquina, por exemplo, um viés <em>indutivo</em> é apenas o conjunto de suposições que um agente usa para derivar previsões de um conjunto de dados. Aqui, o agente é “enviesado” no sentido de que ele foi orientado em uma direção específica; mas, uma vez que aquela direção pode ser a <em>verdade</em>, não é uma coisa ruim para um agente ter um viés indutivo. É valioso e necessário. Isto distingue o “viés” indutivo muito claramente dos outros tipos de viés.</note>
      <note>Uma triste coincidência: Leonard Nimoy, o ator que interpretou Spock, faleceu poucos dias antes do lançamento deste livro. Apesar de citar seu personagem como um exemplo clássico da falsa “racionalidade de Hollywood”, não queremos desrespeitar, de forma alguma, a memória de Nimoy.</note>
      <note>Timothy D. Wilson et al., “Introspecting About Reasons Can Reduce Post-choice Satisfaction,” <em>Personality and Social Psychology Bulletin</em> 19 (1993): 331–331.</note>
      <note>Jamin Brett Halberstadt and Gary M. Levine, “Effects of Reasons Analysis on the Accuracy of Predicting Basketball Games,” <em>Journal of Applied Social Psychology</em> 29, no. 3 (1999): 517–530.</note>
      <note>Keith E. Stanovich and Richard F. West, “Individual Differences in Reasoning: Implications for the Rationality Debate?,” <em>Behavioral and Brain Sciences</em> 23, no. 5 (2000): 645–665, <a target="_blank" href="http://journals.cambridge.org/abstract_S0140525X00003435">http://journals.cambridge.org/abstract_S0140525X00003435</a>.</note>
      <note>Timothy D. Wilson, David B. Centerbar, and Nancy Brekke, “Mental Contamination and the Debiasing Problem,” in <em>Heuristics and Biases: The Psychology of Intuitive Judgment</em>, ed. Thomas Gilovich, Dale Griffin, and Daniel Kahneman (Cambridge University Press, 2002).</note>
      <note>Amos Tversky and Daniel Kahneman, “Extensional Versus Intuitive Reasoning: The Conjunction Fallacy in Probability Judgment,” <em>Psychological Review</em> 90, no. 4 (1983): 293–315, <span class="doi">doi</span>:10.1037/0033-295X.90.4.293.</note>
      <note>Richards J. Heuer, <em>Psychology of Intelligence Analysis</em> (Center for the Study of Intelligence, Central Intelligence Agency, 1999).</note>
      <note>Wayne Weiten, Psychology: Themes and Variations, Briefer Version, Eighth Edition (Cengage Learning, 2010).</note>
      <note>Raymond S. Nickerson, “Confirmation Bias: A Ubiquitous Phenomenon in Many Guises,” <em>Review of General Psychology</em> 2, no. 2 (1998): 175.</note>
      <note>
        <em>Negligência da probabilidade</em> é um outro viés cognitivo. Nos meses e anos que se seguiram ao 11 de setembro, muitas pessoas optaram por dirigir longas distâncias ao invés de voar. Sequestro não era algo <em>provável</em>, mas agora parecia que era uma carta sobre a mesa; a mera possibilidade de sequestro impactava as decisões enormemente. Ao confiar em um raciocínio preto-e-branco (carros e aviões são “seguros” ou “inseguros”, ponto final), as pessoas na verdade se colocavam em um perigo muito maior. Embora eles devessem ter pesado a probabilidade de morrer em uma viagem de carro através do país contra a probabilidade de morrer em um vôo através do país – a primeira morte é centenas de vezes mais provável –, eles contaram com o seu sentimento geral de preocupação e ansiedade (a heurística do afeto). Podemos ver o mesmo padrão de comportamento em crianças que, ao ouvir os argumentos a favor e contra a segurança dos cintos de segurança, vão e voltam em sua opinião sobre se cintos de segurança são uma ideia completamente boa ou completamente ruim, em vez de tentar comparar os pesos das considerações a favor e contra<ref>21</ref>.
        <p>Alguns outros exemplos de vieses são: a <em>regra do pico/final</em> (avaliar eventos relembrados com base em seu momento mais intenso, e em como eles acabaram); <em>ancoragem</em> (basear suas decisões em informações recentemente encontradas, mesmo quando irrelevantes)<ref>22</ref> e <em>auto-ancoragem</em> (usar a si próprio como um modelo de características prováveis dos outros sem ponderar suficientemente os sentidos nos quais você é atípico)<ref>23</ref>; e o <em>viés do status quo</em> (favorecer excessivamente o que é normal e esperado contra o que é novo e diferente).<ref>24</ref></p>
      </note>
      <note>Katherine Hansen et al., “People Claim Objectivity After Knowingly Using Biased Strategies,” <em>Personality and Social Psychology Bulletin</em> 40, no. 6 (2014): 691–699.</note>
      <note>Da mesma forma, Pronin escreve a respeito da cegueira ao viés de gênero:
        <blockquote>Em um estudo, os participantes consideraram um candidato e uma candidata a um emprego de chefe de polícia e, em seguida, avaliaram se “ser malandro” <em>[streetwise no original]</em> ou “ter educação formal” era mais importante para o trabalho. O resultado foi que os participantes favoreceram aquela característica que, segundo haviam sido informados, era possuída pelo candidato do sexo masculino (por exemplo, se lhes havia sido dito que ele era “malandro”, eles viam isso como mais importante). Os participantes eram completamente cegos para esse viés de gênero; de fato, quanto mais objetivos eles achavam que tinham sido, maior era o viés que eles realmente demonstravam<ref>25</ref>.</blockquote>
        Mesmo quando sabemos sobre vieses, Pronin observa, continuamos sendo “realistas ingênuos” a respeito de nossas próprias crenças. Consistentemente tornamos a tratar nossas crenças como se fossem representações sem distorção de como as coisas realmente são<ref>26</ref>.
      </note>
      <note>Em uma pesquisa com 76 pessoas à espera em aeroportos, os indivíduos classificaram-se como muito menos suscetíveis a vieses cognitivos, em média, do que uma pessoa normal no aeroporto. Em particular, as pessoas se acham especialmente imparciais quando o viés é socialmente indesejável ou tem consequências difíceis de notar.<ref>27</ref> Outros estudos constataram que as pessoas com laços pessoais em relação a um problema acreditam que esses laços melhoram a sua compreensão e objetividade; mas quando vêem <em>outras pessoas</em> que exibem os <em>mesmos</em> laços, eles inferem que essas pessoas estão excessivamente apegadas e enviesadas.</note>
      <note>Joyce Ehrlinger, Thomas Gilovich, and Lee Ross, “Peering Into the Bias Blind Spot: People’s Assessments of Bias in Themselves and Others,” <em>Personality and Social Psychology Bulletin</em> 31, no. 5 (2005): 680–692.</note>
      <note>Richard F. West, Russell J. Meserve, and Keith E. Stanovich, “Cognitive Sophistication Does Not Attenuate the Bias Blind Spot,” <em>Journal of Personality and Social Psychology</em> 103, no. 3 (2012): 506.</note>
      <note>Não devem ser confundidas com as pessoas que acham que são especialmente inteligentes, atenciosas etc. por causa do viés da superioridade ilusória.</note>
      <note>Michael J. Liersch and Craig R. M. McKenzie, “Duration Neglect by Numbers and Its Elimination by Graphs,” <em>Organizational Behavior and Human Decision Processes</em> 108, no. 2 (2009): 303–314.</note>
      <note>Sebastian Serfas, Cognitive Biases in the Capital Investment Context: Theoretical Considerations and Empirical Experiments on Violations of Normative Rationality (Springer, 2010).</note>
      <note>Zhuangzi and Burton Watson, <em>The Complete Works of Zhuangzi</em> (Columbia University Press, 1968).</note>
      <note>Cass R. Sunstein, “Probability Neglect: Emotions, Worst Cases, and Law,” <em>Yale Law Journal</em> (2002): 61–107.</note>
      <note>Dan Ariely, Predictably Irrational: The Hidden Forces That Shape Our Decisions (HarperCollins, 2008).</note>
      <note>Boaz Keysar and Dale J. Barr, “Self-Anchoring in Conversation: Why Language Users Do Not Do What They ‘Should,’” in <em>Heuristics and Biases: The Psychology of Intuitive Judgment</em>, ed. Thomas Gilovich, Dale Griffin, and Daniel Kahneman (New York: Cambridge University Press, 2002), 150–166, <span class="doi">doi</span>: 10.2277/0521796792.</note>
      <note>Scott Eidelman and Christian S. Crandall, “Bias in Favor of the Status Quo,” <em>Social and Personality Psychology Compass</em> 6, no. 3 (2012): 270–281.</note>
      <note>Eric Luis Uhlmann and Geoffrey L. Cohen, “‘I think it, therefore it’s true’: Effects of Self-perceived Objectivity on Hiring Discrimination,” <em>Organizational Behavior and Human Decision Processes</em> 104, no. 2 (2007): 207–223.</note>
      <note>Emily Pronin, “How We See Ourselves and How We See Others,” <em>Science</em> 320 (2008): 1177–1180, <a target="_blank" href="http://psych.princeton.edu/psychology/research/pronin/pubs/2008%20Self%20and%20Other.pdf">http://psych.princeton.edu/psychology/research/pronin/pubs/2008%20Self%20and%20Other.pdf</a></note>
      <note>Emily Pronin, Daniel Y. Lin, and Lee Ross, “The Bias Blind Spot: Perceptions of Bias in Self versus Others,” <em>Personality and Social Psychology Bulletin</em> 28, no. 3 (2002): 369–381.</note>
    </notes>

  </article>

</section>

<section id="book-i"><h1 class="book-title">I - Mapa e Território</h1>

  <section id="seq-a"><h1 class="seq-title">A. Previsivelmente Errado</h1>

    <article id="art-1"><h1>1. O que quero dizer com “racionalidade”?</h1>

      <p>Quero dizer:</p>
      <ol>
        <li><strong>Racionalidade epistêmica</strong>: melhorar sistematicamente a precisão de suas crenças.</li>
        <li><strong>Racionalidade instrumental</strong>: alcançar sistematicamente os seus valores.</li>
      </ol>
      <p>Quando você abrir os olhos e olhar para o quarto ao seu redor, você vai localizar seu laptop próximo à mesa, e vai localizar uma estante próxima à parede. Se algo der errado com seus olhos, ou com seu cérebro, então o seu modelo mental pode dizer que há uma estante onde não existe estante alguma, e quando você for até lá para pegar um livro, você vai se desapontar.</p>
      <p>Isso é ter uma crença falsa, um mapa do mundo que não corresponde ao território. Racionalidade epistêmica tem a ver com construir mapas que sejam precisos. Esta correspondência entre crença e realidade é comumente chamada de “<a target="_blank" href="http://racionalidade.com.br/wiki/Interlude:_The_Simple_Truth" title="Interlude: The Simple Truth">verdade</a>”, e eu fico feliz em chamá-la assim.</p>
      <p>Racionalidade instrumental, por outro lado, tem a ver com <em>dirigir</em> a realidade &mdash; mandar o futuro para onde você quer que ele vá. É a arte de escolher ações que levam a resultados classificados como melhores segundo as suas preferências. Eu, às vezes, chamo isso de “vencer”.</p>
      <p>Assim, racionalidade tem a ver com formar crenças verdadeiras e tomar decisões vencedoras.</p>
      <p>Perseguir a “verdade”, aqui, não significa dispensar evidências incertas ou indiretas. Olhar para o quarto ao seu redor e construir um mapa mental dele não é diferente, em princípio, de acreditar que a Terra tem um núcleo derretido, ou que Júlio César era careca. Estas questões, por estarem distantes de você no espaço e no tempo, podem parecer mais etéreas e abstratas do que questões a respeito da sua estante. No entanto, há fatos reais sobre o estado do núcleo da Terra em 2015 DC e sobre o estado da cabeça de César em 50 AC. Esses fatos podem ter efeitos reais sobre você, mesmo que você nunca encontre uma maneira de ficar face-a-face com César ou com o núcleo.</p>
      <p>E “vencer”, aqui, não precisa vir à custa dos outros. O projeto de vida pode ter como foco a colaboração ou auto-sacrifício, em vez da concorrência. “Seus valores”, aqui, significa <em>qualquer coisa com que você se importa</em>, inclusive outras pessoas. Ele não se limita a valores <em>egoístas</em> ou valores <em>não partilhados</em>.</p>
      <p>Quando as pessoas dizem “X é racional!”, normalmente é apenas uma maneira mais estridente de dizer “eu acho que X é verdadeiro” ou “eu acho que X é bom.” Então, por que ter uma palavra a mais para “racional”, além de “verdadeiro” e “bom”?</p>
      <p>Um argumento análogo pode ser dado contra o uso de “verdade”. Não há necessidade de dizer “é verdade que a neve é branca” quando você pode simplesmente dizer “a neve é branca”. O que torna a idéia de verdade útil é que ela nos permite falar sobre as características gerais da correspondência entre mapa e território. “Modelos verdadeiros costumam produzir previsões experimentais melhores do que modelos falsos” é uma generalização útil, e você não consegue fazê-la sem usar um conceito como “verdadeiro” ou “preciso”.</p>
      <p>Da mesma forma, “agentes racionais tomam decisões que maximizam a expectativa probabilística de uma função de utilidade coerente” é o tipo de pensamento que depende de um conceito de racionalidade (instrumental), enquanto que “é racional comer vegetais” provavelmente pode ser substituído por “é útil comer vegetais” ou “é de seu interesse comer vegetais”. Precisamos de um conceito como “racional” a fim de observar fatos gerais sobre essas formas de pensar que sistematicamente produzem verdade ou valor &mdash; e os modos sistemáticos pelos quais falhamos em alcançar esses padrões.</p>
      <p>Às vezes, psicólogos experimentais descobrem raciocínios humanos que parecem muito estranhos. <a href="http://lesswrong.com/lw/ji/conjunction_fallacy/">Por exemplo</a>, alguém classifica a probabilidade de que “Bill toca jazz” como <em>menor</em> do que a probabilidade de que “Bill é um contador que toca jazz”. Este parece ser um julgamento estranho, uma vez que qualquer contador que toca jazz é, obviamente, uma pessoa que toca jazz. Mas a que ponto de vista superior recorremos para dizer que a avaliação é <em>errada</em>?</p>
      <p>Os psicólogos experimentais usam dois padrões de ouro: <em>teoria da probabilidade</em> e <em>teoria da decisão</em>.</p>
      <p>A teoria da probabilidade é o conjunto de leis subjacentes à crença racional. A matemática da probabilidade descreve igualmente e sem distinção como (a) descobrir onde sua estante está, (b) descobrir a temperatura do núcleo da Terra, e (c) estimar quantos fios de cabelos havia na cabeça de Júlio César. É tudo o mesmo problema de como processar as evidências e observações para rever (“atualizar”) suas crenças. De forma similar, a teoria da decisão é o conjunto de leis subjacentes à ação racional, e é igualmente aplicável independentemente do quais são as suas metas e opções disponíveis.</p>
      <p>Defina “P(tal-e-tal)” como “a probabilidade de que tal-e-tal aconteça”, e P(A,B) como “a probabilidade de que A e B ambos aconteçam.” Uma vez que é uma lei universal da teoria da probabilidade que P(A) &#8805; P(A,B), o juízo de que P(Bill toca jazz) é menor que P(Bill toca jazz, Bill é um contador) é considerado incorreto.</p>
      <p>No jargão técnico, diz-se que esse juízo de probabilidade é <em>não-Bayesiano</em>. Crenças e ações que são racionais, nesse sentido matematicamente bem definido, são chamados de “Bayesianos”.</p>
      <p>Note que o conceito moderno de racionalidade não é sobre o raciocínio verbal. Eu dei o exemplo de abrir os olhos, olhar ao seu redor, e construir um modelo mental de uma sala contendo uma estante contra a parede. O conceito moderno de racionalidade é geral o suficiente para incluir seus olhos e áreas visuais do seu cérebro como coisas-que-mapeiam. Ele inclui suas intuições não-verbais também. A matemática não se importa se usamos a mesma palavra em português, “racional”, para se referir a Spock e ao Bayesianismo. A matemática modela boas maneiras de alcançar metas ou mapear o mundo, independentemente de se essas formas se encaixam em nossos preconceitos e estereótipos sobre o que a “racionalidade” deve ser.</p>
      <p>Isso não chega a esgotar o problema do que se quer dizer, na prática, por “racionalidade”, por duas razões principais:</p>
      <p>Em primeiro lugar, os formalismos Bayesianos em sua forma plena são computacionalmente intratáveis na maioria dos problemas do mundo real. Ninguém consegue <em>realmente</em> calcular e obedecer a matemática, assim como você não consegue prever o mercado de ações calculando os movimentos dos quarks.</p>
      <p>É por isso que existe um site inteiro chamado “Less Wrong <em>[Menos Errado]</em>”, ao invés de uma única página que simplesmente indica os axiomas formais e encerra o assunto. Há ainda toda uma arte de encontrar a verdade e alcançar valor <em>a partir de uma mente humana</em>: temos que aprender nossas próprias falhas, superar nossos vieses, nos impedir de enganar a nós mesmos, nos preparar emocionalmente para encarar a verdade e fazer o que precisa ser feito, et cetera, et cetera.</p>
      <p>Em segundo lugar, às vezes o próprio significado da matemática é colocado em questão. As regras exatas da teoria das probabilidades são colocadas em questão, por exemplo, por <a href="http://www.anthropic-principle.com/?q=anthropic_principle/primer">problemas antrópicos</a> em que o número de observadores é incerto. As regras exatas da teoria da decisão são colocadas em questão, por exemplo, por <a href="http://racionalidade.com.br/wiki/Newcomb%E2%80%99s_Problem_and_Regret_of_Rationality" title="Newcomb’s Problem and Regret of Rationality">problemas como o de Newcomb</a> em que outros agentes podem prever a sua decisão antes que aconteça.<ref>1</ref></p>
      <p>Em casos como esses, é inútil tentar resolver o problema inventando <a href="http://racionalidade.com.br/wiki/The_Parable_of_Hemlock" title="The Parable of Hemlock">uma nova definição</a> para a palavra “racional” e dizendo: “Portanto, a minha resposta preferida, <a href="http://racionalidade.com.br/wiki/Arguing_%22By_Definition%22" title="Arguing &quot;By Definition&quot;"><em>por definição</em></a>, é o que significa a palavra ‘racional’”. Isso simplesmente levanta a questão de por que alguém deve prestar atenção à sua definição. Eu não estou interessado na teoria da probabilidade porque é a santa palavra transmitida por Laplace. Eu me interesso pela a atualização de crenças no estilo Bayesiano (<a href="http://racionalidade.com.br/wiki/Occam%27s_Razor" title="Occam’s Razor">com prévias Occamianas</a>) porque espero que este estilo de pensamento nos leve sistematicamente mais perto da, você sabe, <em>precisão</em>, do mapa que reflete o território.</p>
      <p>E depois há as questões sobre como pensar que parecem não ser bem respondidas seja pela teoria da probabilidade, seja pela teoria da decisão – como a questão de <a href="#art-2" title="Sentindo-se Racional">como se sentir a respeito da verdade, quando você a possui</a>. Aqui, mais uma vez, tentar definir “racionalidade” de alguma forma específica não apoia uma resposta, apenas pressupõe uma.</p>
      <p>Eu não estou aqui para discutir sobre <a href="http://racionalidade.com.br/wiki/Disputing_Definitions" title="Disputing Definitions">o significado de uma palavra</a>, nem mesmo se essa palavra é “racionalidade”. O objetivo de vincular sequências de letras a conceitos particulares é <a href="http://racionalidade.com.br/wiki/The_Argument_from_Common_Usage" title="The Argument from Common Usage">permitir que duas pessoas <em>se comuniquem</em></a> – para ajudar a transportar pensamentos de uma mente a outra. Você não pode mudar a realidade, ou provar o pensamento, manipulando quais significados seguem quais palavras.</p>
      <p>Então, se você entende qual conceito eu estou <em>querendo passar, de forma geral,</em> com esta palavra “racionalidade”, e com o sub-termos “racionalidade epistêmica” e “racionalidade instrumental”, nós <em>nos comunicamos</em>: alcançamos tudo o que se pode alcançar ao discutir como definir “racionalidade”. O que resta para discutir não é <em>que significado</em> vincular às sílabas “ra-cio-na-li-da-de”; o resta para discutir é <em>qual é uma boa maneira de pensar</em>.</p>
      <p>Se você diz, “É (epistemologicamente) racional que eu acredite em X, mas a verdade é Y”, então provavelmente você está usando a palavra “racional” com um significado diferente do que eu tenho em mente. (Por exemplo, a “racionalidade” deve ser <em>consistente sob reflexão</em> &mdash; “racionalmente” olhar para as evidências e “racionalmente” ponderar como sua mente processa as evidências não deve levar a duas conclusões diferentes.)</p>
      <p>Da mesma forma, se você se pegar dizendo, “A coisa (instrumentalmente) racional a fazer é X, mas a coisa certa a fazer é Y”, então você está quase certamente usando algum outro significado para a palavra “racional” ou para a palavra “certo”. Eu uso o termo “racionalidade” <em>normativamente</em> , para especificar os padrões desejáveis de pensamento.</p>
      <p>Neste caso &mdash; ou em qualquer outro caso em que as pessoas discordem sobre significados de palavras &mdash; você deve <a href="http://racionalidade.com.br/wiki/Taboo_Your_Words" title="Taboo Your Words">usar uma linguagem mais específica</a> no lugar de “racional”: “a coisa auto-benéfica a fazer é fugir, mas eu espero que eu iria pelo menos tentar arrastar a criança para fora dos trilhos da ferrovia”, ou “a Teoria Causal da Decisão, como usualmente formulada, diz que você deve pegar as duas caixas no <a href="http://racionalidade.com.br/wiki/Newcomb%27s_Problem_and_Regret_of_Rationality" title="Newcomb’s Problem and Regret of Rationality">Problema de Newcomb</a>, mas eu prefiro ganhar um milhão de dólares.”</p>
      <p>Na verdade, eu recomendo a releitura deste ensaio, substituindo todas as ocorrências de “racional” por “fuzal”, e ver se isso muda as conotações do que eu estou dizendo qualquer. Se assim for, eu digo: não se esforcem em busca da racionalidade, mas da fuzalidade.</p>
      <p>A palavra “racional” tem armadilhas em potencial, mas há uma abundância de casos <em>não</em>-limítrofes em que “racional” funciona bem para comunicar o que eu estou pensando. Assim como “irracional”. Nesses casos, eu não tenho medo de usar essas palavras.</p>
      <p>No entanto, deve-se ter cuidado para não <em>abusar</em> da palavra. Você não recebe pontos simplesmente para pronunciá-la em voz alta. Se você falar em demasia sobre o Caminho, você não vai alcançá-lo.</p>

      <p class="endlink"><a target="_blank" href="http://lesswrong.com/lw/31/what_do_we_mean_by_rationality/"></a></p>

      <notes>
        <note><strong>Nota do Editor:</strong> Para uma boa introdução para o problema de Newcomb, ver <a href="http://www.slate.com/articles/arts/egghead/2002/02/thinkinginside_the_boxes.single.html">Holt</a>.<ref>2</ref> De modo mais geral, você pode encontrar definições e explicações para muitos dos termos deste livro no site <a href="http://wiki.lesswrong.com/wiki/RAZ_Glossary">http://wiki.lesswrong.com/wiki/RAZ_Glossary</a></note>
        <note>Jim Holt, “Thinking Inside the Boxes,” <em>Slate</em> (2002), <a href="http://www.slate.com/articles/arts/egghead/2002/02/thinkinginside%5C_the%5C_boxes.single.html">http://www.slate.com/articles/arts/egghead/2002/02/thinkinginside%5C_the%5C_boxes.single.html</a></note>
      </notes>

    </article>

    <article id="art-2"><h1>2. Sentindo-se racional</h1>

      <p>Uma crença popular sobre a “racionalidade” é que a racionalidade se opõe a toda emoção &mdash; que toda a nossa tristeza e toda a nossa alegria são automaticamente anti-lógicas em virtude de serem <em>sentimentos</em>. No entanto, estranhamente, eu não consigo encontrar qualquer teorema da teoria da probabilidade que prove que eu devo parecer frio e sem expressão.</p>
      <p>Então, a racionalidade seria ortogonal aos sentimentos? Não; nossas emoções surgem dos nossos modelos da realidade. Se eu acredito que o meu irmão morto foi encontrado vivo, eu vou ficar feliz; se eu acordar e perceber que era um sonho, vou ficar triste. P.C. Hodgell disse: “O que pode ser destruído pela verdade deve ser”. A felicidade do meu eu que sonhava se opunha à verdade. Minha tristeza ao acordar é racional; não há verdade que a destrua.</p>
      <p>A racionalidade começa por se perguntar como-o-mundo-é, mas se espalha viralmente a qualquer outro pensamento que dependa de como nós pensamos que o mundo é. Suas crenças sobre “como-o-mundo-é” podem se referir a qualquer coisa que você acha que está lá fora, na realidade, qualquer coisa que existe ou não existe, qualquer membro da classe de “coisas que podem fazer outras coisas acontecerem”. Se você acredita que há um duende em seu armário que amarra os cadarços de seus sapatos juntos, então esta é uma crença sobre como-o-mundo-é. Seus sapatos são reais, você pode pegá-los. Se há algo lá fora que pode chegar e amarrar seus cadarços, ele deve ser real também, parte da vasta rede de causas e efeitos que nós chamamos de “universo”.</p>
      <p><em>Sentir-se irritado</em> com o duende que amarrou seus cadarços envolve um estado de espírito que não tem a ver <em>apenas</em> como como-o-mundo-é. Suponha que, como um budista, ou um paciente de lobotomia ou apenas uma pessoa muito fleumática, encontrar seus cadarços amarrados não o tenha deixado irritado. Isto não afetaria o que você espera ver no mundo &mdash; você ainda esperaria abrir seu armário e encontrar seus cadarços amarrados. Sua raiva ou calma não deveriam afetar o seu melhor palpite aqui, porque o que acontece em seu armário não depende de seu estado emocional; embora possa ser preciso algum esforço para pensar tão claramente.</p>
      <p>Mas o sentimento de raiva está emaranhado com um estado mental que <em>é</em> sobre como-o-mundo-é; você fica com raiva <em>porque</em> você acha que o duende amarrou os cadarços do seus tênis. O critério de racionalidade se espalha de forma viral, a partir da pergunta inicial da existência ou não de um duende que amarrou os seus tênis, para a raiva resultante.</p>
      <p>Tornar-se mais racional &mdash; chegar a melhores estimativas de como-o-mundo-é &mdash; pode diminuir sentimentos <em>ou intensificá-los</em>. Às vezes fugimos de sentimentos intensos, negando os fatos, recuando para longe da visão do mundo que deu origem à emoção poderosa. Se for este o caso, então conforme você estudar as habilidades de racionalidade e se treinar para não negar os fatos, seus sentimentos se tornarão mais fortes.</p>
      <p>Nos meus primórdios, eu nunca tinha certeza se estava <em>tudo bem</em> sentir as coisas fortemente &mdash; se era permitido, se era adequado. Eu não acho que essa confusão surgiu apenas da minha incompreensão juvenil da racionalidade. Tenho observado problemas semelhantes em pessoas que nem sequer aspiram a ser racionalistas; quando estão felizes, eles se perguntam se eles realmente estão autorizados a ser felizes, e quando eles estão tristes, eles nunca têm certeza se devem fugir da emoção ou não. Desde os dias de Sócrates, pelo menos, e provavelmente muito antes, a maneira de parecer culto e sofisticado tem sido nunca deixar ninguém ver você se importar fortemente com alguma coisa. É <em>embaraçoso</em> sentir &mdash; simplesmente não se faz na sociedade educada. Você deveria ver os olhares estranhos que recebo quando as pessoas percebem o quanto eu me importo com racionalidade. Não é o assunto incomum, eu acho, mas é que eles não estão acostumados a ver adultos sãos que visivelmente se preocupam com <em>alguma coisa</em>.</p>
      <p>Mas eu sei, agora, que não há nada de errado com sentir intensamente. Desde que adotei a regra de “O que pode ser destruído pela verdade deve ser”, eu também vim a perceber que “Aquilo que a verdade nutre deve prosperar”. Quando acontece alguma coisa boa, eu fico feliz, e não há nenhuma confusão em minha mente sobre se é racional eu ficar feliz. Quando <a target="_blank" href="http://yudkowsky.net/other/yehuda/">algo terrível acontece</a>, eu não fujo da minha tristeza procurando falsas consolações e falsos lados bons. Eu visualizo o passado e o futuro da humanidade, as dezenas de bilhões de mortes ao longo da nossa história, a miséria e o medo, a busca por respostas, as mãos trêmulas esticando-se para fora de tanto sangue, o que poderemos nos tornar um dia, quando fizermos das estrelas nossas cidades, toda aquela escuridão e toda aquela luz &mdash; eu sei que eu nunca poderei realmente entender, e eu não tenho as palavras para dizer. Apesar de toda a minha filosofia, eu ainda tenho vergonha de confessar emoções fortes, e provavelmente você está desconfortável em ouvi-las. Mas eu sei, agora, que é racional sentir.</p>

      <p class="endlink"><a target="_blank" href="http://lesswrong.com/lw/hp/feeling_rational/"></a></p>

    </article>

    <article id="art-3"><h1>3. Por que a verdade? E...</h1>

      <p>Alguns dos comentários no <em><a target="_blank" href="http://www.overcomingbias.com/">Overcoming Bias</a></em> tocaram na questão de por que nós deveríamos buscar a verdade (felizmente, não muitos questionaram <a target="_blank" href="http://racionalidade.com.br/wiki/Interlude:_The_Simple_Truth" title="Interlude: The Simple Truth">o que é a verdade</a>). Nossa motivação definidora para conformar os nossos pensamentos à racionalidade, que determina se uma dada configuração é “boa” ou “ruim”, vem de qualquer que seja o motivo para nós querermos descobrir a verdade, para início de conversa.</p>
      <p>Está escrito: “A primeira virtude é a curiosidade”. A curiosidade é uma razão para buscar a verdade, e pode não ser a única, mas ela tem uma pureza especial e admirável. Se a sua motivação é a curiosidade, você irá priorizar suas questões na medida em que as questões, por elas mesmas, provocarem o seu senso estético pessoal. Um desafio mais difícil, com uma maior probabilidade de falha, pode valer mais o esforço do que um mais simples, só porque é mais divertido.</p>
      <p>Como já observei, as pessoas muitas vezes pensam em racionalidade e emoções como inimigas. Como a curiosidade é uma emoção, eu suspeito que algumas pessoas vão se opor a tratar a curiosidade como parte da racionalidade. De minha parte, eu classifico uma emoção como “não racional” se ela se apoia em crenças equivocadas, ou ainda, em uma conduta epistêmica que conduz a erros: “Se o ferro se aproxima de seu rosto, e você acredita que ele esteja quente, e ele está frio, o Caminho se opõe ao seu medo. Se o ferro se aproxima de seu rosto, e você acredita que ele esteja frio, e ele está quente, o Caminho se opõe a sua calma”. Em contrapartida, então, uma emoção que é evocada por uma crença correta ou pelo pensamento epistemicamente racional é uma “emoção racional”; e isso tem a vantagem de nos permitir ver a calma como um estado emocional, em vez de como um padrão neutro privilegiado.</p>
      <p>Quando as pessoas pensam sobre “emoção” e “racionalidade” como opostos, eu suspeito que eles estão, na verdade, pensando sobre o Sistema 1 e o Sistema 2 – juízos perceptivos rápidos versus juízos deliberativos lentos. Juízos deliberativos não são sempre verdadeiros, e juízos perceptivos não são sempre falsos; então é muito importante distinguir essa dicotomia da “racionalidade”. Ambos os sistemas podem servir à meta da verdade, ou prejudicá-la, de acordo com como são usados.</p>
      <p>Além de pura curiosidade emocional, quais outros motivos existem para desejar a verdade? Bom, você pode querer realizar algum objetivo específico do mundo real, como construir um avião e, por conseguinte, você precisa saber algumas verdades específicas sobre aerodinâmica. Ou, mais mundanamente, você quer leite achocolatado, e, portanto, precisa saber se o supermercado local tem leite achocolatado, para que você possa escolher entre ir para lá ou para outro lugar. Se essa é a razão pela qual você quer a verdade, então a prioridade que você atribui para as suas questões irá refletir a utilidade esperada da informação delas decorrente – o quanto as respostas possíveis influenciam as suas escolhas, o quanto as suas escolhas importam, e o quanto você espera encontrar uma resposta que mude sua escolha padrão.</p>
      <p>Procurar a verdade meramente por seu valor instrumental pode parecer impuro – nós não deveríamos desejar a verdade por ela própria? – mas tais investigações são extremamente importantes porque elas criam um critério de verificação exterior: se o seu avião cai do céu, ou se você vai à loja e não encontra achocolatado, isso é uma pista de que você fez algo de errado. Você recebe feedback sobre quais modos de pensar funcionam, e quais não funcionam. A curiosidade pura é algo maravilhoso, mas ela pode não se ocupar muito em verificar suas respostas, uma vez que o mistério atraente tenha desaparecido. Curiosidade, como uma emoção humana, existe desde muito antes dos gregos antigos. Mas o que colocou a humanidade firmemente no caminho da Ciência foi perceber que certos modos de pensar revelavam crenças que nos permitem <em>manipular o mundo</em>. No que diz respeito à curiosidade, tecer contos de fogueira sobre deuses e heróis satisfazia esse desejo igualmente bem, e ninguém se dava conta de que algo estivesse errado com isso.</p>
      <p>Há motivos para buscar a verdade além de curiosidade e pragmatismo? A terceira razão que eu consigo pensar é a moralidade: você acredita que buscar a verdade é nobre e importante e vale a pena. Embora tal ideal também atribua um valor intrínseco à verdade, ela é um estado mental bastante diferente da curiosidade. Estar curioso sobre o que há atrás da cortina não é a mesma sensação de acreditar que você tem um dever moral de olhar lá. No último estado mental, é muito mais provável que você acredite que <em>outras</em> pessoas deveriam também olhar atrás da cortina, ou castigá-las se elas deliberadamente fecharem seus olhos. Por essa razão, eu também rotularia como “moralidade” a crença de que a busca pela verdade é pragmaticamente importante <em>para a sociedade</em>, e, por conseguinte, é um dever que compete a todos. Suas prioridades, de acordo com essa motivação, serão determinadas por seus ideais sobre quais verdades são mais importantes (não mais úteis ou mais intrigantes), ou sobre quando, em que circunstâncias, o dever de buscar a verdade é mais forte.</p>
      <p>Eu tendo a suspeitar da moralidade como uma motivação para racionalidade, <em>não</em> porque eu rejeito o ideal moral, mas porque é um convite para certos tipos de confusão. É muito fácil adquirir, como deveres morais aprendidos, modos de pensar que são terríveis erros de passo na dança. Considere o Sr. Spock de <em>Star Trek</em>, um arquétipo ingênuo de racionalidade. O estado emocional de Spock está sempre definido para “calmo”, mesmo quando isso é absurdamente inapropriado. Ele frequentemente oferece muitos dígitos significativos para probabilidades que são grosseiramente descalibradas (por exemplo, “Capitão, se você mover a Enterprise diretamente para dentro desse buraco negro, nossa probabilidade de sobreviver é apenas 2,234%”. No entanto, nove em dez vezes a Enterprise não é destruída. Que tipo de tolo trágico dá quatro dígitos significativos para um número que está errado por duas ordens de magnitude?). Ainda assim, essa imagem popular é como muitas pessoas concebem o dever de ser “racional” – não é de se surpreender que elas não o abracem com toda vontade. Fazer da racionalidade um dever moral é dar a ela todos os terríveis graus de liberdade de um costume tribal arbitrário. As pessoas chegam à resposta errada e então, indignadas, protestam que elas agiram com propriedade, em vez de aprender com o erro.</p>
      <p>E, no entanto, se é para melhorarmos nossas técnicas de racionalidade, indo além dos padrões de desempenho definidos pelos caçadores-coletores, nós precisaremos de crenças deliberadas sobre como pensar corretamente. Quando escrevemos novos programas mentais para nós mesmos, eles começam no Sistema 2, o sistema deliberativo, e apenas lentamente – se em algum momento – são treinados em nosso circuito neural que subjaz ao Sistema 1. Então, se há certos tipos de pensamento que nós descobrirmos que queremos <em>evitar</em> – como, digamos, vieses – isso será representado dentro do Sistema 2 como uma injunção para não pensar dessa forma; um dever professado de evitá-los.</p>
      <p>Se nós queremos a verdade, nós podemos obtê-la mais efetivamente pensando de certas maneiras, em vez de outras; essas são as técnicas de racionalidade. Algumas dessas técnicas de racionalidade envolvem superar uma certa classe de obstáculos, os vieses...</p>

      <p class="endlink"><a target="_blank" href="http://lesswrong.com/lw/go/why_truth_and/"></a></p>

    </article>

    <article id="art-4"><h1>4. ...O que é um viés, mesmo?</h1>

      <p>Um <em>viés</em> é um certo tipo de obstáculo para o nosso objetivo de alcançar a verdade. (Sua natureza de “obstáculo” decorre desse objetivo da verdade.) Entretanto, há muitos obstáculos que não são “vieses”.</p>
      <p>Se nós começarmos diretamente perguntando “O que é um viés?”, ele surge na questão na ordem errada. Como diz o provérbio, “Existem quarenta tipos de loucura, mas apenas um tipo de senso comum”. A verdade é um alvo estreito, uma pequena região a ser acertada no espaço de configuração. “Ela me ama, ela não me ama” pode ser uma questão binária, mas E = mc<sup>2</sup> é um pequeno ponto no espaço de todas as equações, como um bilhete vencedor de loteria no espaço de todos os bilhetes de loteria. O erro não é uma situação excepcional; é o sucesso que é tão improvável a priori que requer uma explicação.</p>
      <p>Nós não tomamos como ponto de partida um dever moral de “reduzir os vieses”, porque vieses são maus e Não São Permitidos. Essa é a maneira de pensar à qual alguém pode ser levado se adquirir um dever deontológico de “racionalidade” por osmose social, o que leva as pessoas a tentar executar técnicas sem entender a razão de ser delas. (O que é ruim e mal e Não É Permitido, de acordo com <em>O senhor está brincando, Sr. Feynman!</em>, que eu li quando era criança.)</p>
      <p>Em vez disso, nós começamos querendo chegar à verdade, por seja lá qual for a razão, e nós encontramos vários obstáculos que se colocam no caminho de nosso objetivo. Esses obstáculos não são completamente diferentes uns dos outros – por exemplo, há obstáculos que têm a ver com não ter poder de computação o suficiente disponível, ou com as informações serem custosas. Acontece, de fato, que um grande grupo de obstáculos parece ter uma certa característica em comum – se aglomerando em uma região do espaço de ‘obstáculos para a verdade’ – e esse aglomerado foi rotulado de “vieses”.</p>
      <p>O que é um viés? Temos como olhar para o aglomerado empírico e encontrar um teste compacto para decidir se algo pertence a ele? Talvez nós descubramos que nós temos nenhuma explicação melhor do que apontar para alguns exemplos extensionais, e torcer para que o interlocutor entenda. Se você é um cientista que acabou de começar a investigar o fogo, pode ser muito mais sábio apontar para uma fogueira e dizer “Fogo é essa coisa laranja, brilhante e quente que está ali”, em vez de dizer “Eu defino fogo como uma transmutação alquímica de substâncias que libera flogisto”. Você não deveria ignorar algo só porque você não é capaz de definí-lo. Eu não posso citar de cabeça as equações da Relatividade Geral, mas, mesmo assim, se eu andar para além de um penhasco, eu vou cair. E podemos dizer o mesmo a respeito dos vieses – eles não vão nos atingir com nem um pouco menos força só porque nós não conseguimos definir o que é um “viés”. Então nós podemos apontar para falácias da conjunção, para confiança excessiva, para as heurísticas da disponibilidade e da representatividade, para a negligência da taxa-base e dizer, “coisas assim”.</p>
      <p>Dito tudo isso, parece que nós chamamos de “vieses” aqueles obstáculos para a verdade que são produzidos, não pelo custo de informações, nem pelo poder limitado de computação, mas pela forma de nossa própria maquinaria mental. Talvez a maquinaria esteja evolutivamente otimizada para propósitos que se opõem ativamente à precisão epistêmica; por exemplo, a maquinaria utilizada para ganhar discussões em contextos políticos adaptativos. Ou a pressão seletiva distorceu a precisão epistêmica; por exemplo, acreditar no que os outros acreditam, para se dar bem socialmente. Ou, no clássico heurística-e-viés, a maquinaria opera com um algoritmo identificável que faz algum trabalho útil, mas também produz erros sistemáticos: a heurística da disponibilidade não é em si mesma um viés, mas ela dá origem a alguns vieses identificáveis e compactamente descritíveis. Nossos cérebros estão fazendo algo de errado, e depois de muita experimentação e/ou muita reflexão, alguém identifica o problema de uma maneira que o Sistema 2 pode compreender; então nós chamamos isso de “viés”. Mesmo que nós não possamos melhorar em nada só por conhecê-lo, ainda assim é uma falha que surge, de uma maneira identificável, de um tipo particular de maquinaria cognitiva – não de ter maquinaria insuficiente, mas sim da própria forma da maquinaria.</p>
      <p>“Vieses” são distintos dos erros que surgem do conteúdo cognitivo, tal como crenças adotadas, ou deveres morais adotados. Nós chamamos esses de “enganos”, em vez de “vieses”, e eles são muito mais fáceis de corrigir, quando nós mesmos os tivermos percebido. (Embora a origem do engano, ou a origem da origem do engano, possa ser, em última instância, um viés.)</p>
      <p>“Vieses” também não se confundem com erros que surgem do dano a um cérebro humano individual, ou de costumes culturais adquiridos; vieses surgem de maquinaria que é universal entre humanos.</p>
      <p>Platão não era “enviesado” porque ele não conhecia a Relatividade Geral – ele não tinha nenhuma maneira de coletar essa informação, sua ignorância não surgiu da forma de sua maquinaria mental. Mas se Platão acreditava que filósofos dariam reis melhores porque ele próprio era um filósofo – e se essa crença, por sua vez, surgisse de um instinto político adaptativo universal de autopromoção, e não porque o pai de Platão disse a ele que todos têm um dever moral de promover sua própria profissão para governar, nem porque Platão cheirou muita cola quando criança – então isso seria um viés, ainda que Platão nunca tenha sido alertado disso.</p>
      <p>Vieses podem não ser baratos para corrigir. Alguns podem nem mesmo ser corrigíveis. Mas nos casos em que olhamos para nossa maquinaria mental e vemos uma explicação causal de uma classe identificável de erros; e quando o problema parece vir da forma evoluída da maquinaria, em vez de vir da maquinaria ser insuficiente, ou de conteúdo específico ruim; então nós chamamos isso de viés.</p>
      <p>Pessoalmente, eu vejo nossa missão em termos de aquisição de habilidades pessoais de racionalidade, de aprimoramento das técnicas de descoberta da verdade. O desafio é obter o objetivo positivo da verdade, não evitar o alvo negativo da falha. O espaço de falha é amplo, erros infinitos de infinita variedade. É difícil descrever um espaço tão gigantesco: “O que é verdade para uma maçã pode não ser para outra maçã; por isso, mais pode ser dito de uma única maçã do que de todas as maçãs do mundo”. O espaço de sucesso é mais restrito e, por conseguinte, mais pode ser dito sobre ele.</p>
      <p>Embora eu não repudie (como se pode ver) discutir definições, nós devemos lembrar que esse não é nosso objetivo primário. Nós estamos aqui para seguir na grande busca humana pela verdade; pois nós temos uma necessidade desesperada de conhecimento, e, além disso, nós somos curiosos. Para alcançarmos esse fim, nos empenhemos para superar sejam quais forem os obstáculos que estejam em nosso caminho, quer nós os chamemos de “vieses”, quer não.</p>

      <p class="endlink"><a target="_blank" href="http://lesswrong.com/lw/gp/whats_a_bias_again/"></a></p>

    </article>

    <article id="art-5"><h1>5. Disponibilidade</h1>

      <p>A <em>heurística da disponibilidade</em> é julgar a frequência ou a probabilidade de um evento pela facilidade com que exemplos do evento vêm à mente.</p>
      <p>Um famoso estudo 1978 por Lichtenstein, Slovic, Fischhoff, Layman, e Combs, “Frequência Avaliada de Eventos Letais” <ref>1</ref>, estudou erros na quantificação da gravidade de riscos, ou na avaliação de qual de dois perigos ocorriam com maior frequência. Sujeitos pensavam que acidentes causavam aproximadamente o mesmo número de mortes que doenças; achavam que homicídio era uma causa de morte mais frequente que suicídio. Na verdade, doenças causam cerca de dezesseis vezes mais mortes que acidentes e suicídios são duas vezes mais frequentes que homicídios.</p>
      <p>Uma hipótese óbvia para explicar estas crenças distorcidas é que os assassinatos têm mais chance de serem objeto de comentários do que suicídios; portanto, é mais provável que alguém se lembre de ter ouvido de um assassinato do que de um suicídio. Acidentes são mais dramáticos do que doenças; talvez isso faça com que as pessoas sejam mais propensas a memorizar, ou mais propensas a lembrar, de um acidente. Em 1979, um estudo seguinte por Combs e Slovic mostrou que os juízos de probabilidade distorcidos tinham forte correlação (0,85 e 0,89) com as distorcidas frequências de notícias em dois jornais <ref>2</ref>. Isso não resolveu a questão de se os assassinatos estão mais disponíveis na memória porque eles são mais noticiados, ou se os jornais reportam mais sobre assassinatos porque assassinatos são mais vívidos (e portanto, também mais lembrados). Mas, de qualquer forma, um viés de disponibilidade está operando. Divulgação seletiva é uma importante fonte de vieses de disponibilidade. No ambiente ancestral, a maior parte do que você sabia vinha de experiências que você mesmo tinha tido; ou você ouvira diretamente de um companheiro de tribo que tinha visto. Geralmente havia no máximo uma camada de divulgação seletiva entre você e o próprio evento. Com a Internet de hoje, você pode ver relatos que passaram pelas mãos de seis blogueiros no caminho até você &mdash; seis filtros sucessivos. Em comparação com os nossos antepassados, nós vivemos em um mundo maior, em que muito mais acontece, e uma parte muito menor dele chega até nós &mdash; o efeito de seleção é muito mais forte, o que pode criar vieses de disponibilidade muito maiores.</p>
      <p>Na vida real, é improvável que você você um dia encontre com o Bill Gates. Mas, graças à divulgação seletiva pela mídia, você pode ser tentado a comparar o seu sucesso na vida ao dele &mdash; e sofrer as penalidades hedônicas correspondentes. A frequência objetiva de Bill Gates é 0,00000000015, mas você ouve falar dele com muito mais frequência. Por outro lado, 19% do planeta vive com menos de US $1/dia, e eu duvido que um quinto dos posts de blog que você lê são escritos por eles.</p>
      <p>Usar a disponibilidade parece dar origem a um <a target="_blank" href="http://lesswrong.com/lw/j4/absurdity_heuristic_absurdity_bias/">viés do absurdo</a>; eventos que nunca aconteceram não são lembrados e, portanto, considerados como tendo probabilidade zero. Quando não há inundações na história recente (e ainda assim as probabilidades são bastante calculáveis), as pessoas se recusam a comprar seguro contra inundações, mesmo quando ele é fortemente subsidiado e com preço muito abaixo de um valor atuarialmente justo. Kunreuther et al. sugerem que essa sub-reação a ameaças de inundação podem surgir da “incapacidade dos indivíduos de conceituar inundações que nunca ocorreram... Homens em planícies de inundação parece ser muito prisioneiros de sua experiência... Inundações experimentadas recentemente parecem definir um limite superior para o tamanho da perda com que os gestores acreditam que eles deveriam se preocupar.” <ref>3</ref>.</p>
      <p>Burton et al. relatam que, quando barragens e diques são construídos, eles reduzem a frequência das inundações, e assim, aparentemente, criam uma falsa sensação de segurança, levando a precauções reduzidas <ref>4</ref>. Embora a construção de barragens diminua a <em>frequência</em> das inundações, os danos <em>por inundação</em> depois são tão maiores que a média anual de dano <em>aumenta.</em> O sábio seria extrapolar a partir da memória de pequenos perigos para a possibilidade de grandes perigos. Em vez disso, a experiência passada de pequenos perigos parece definir um limite superior para o risco percebido. Uma sociedade bem protegida contra os riscos menores não toma nenhuma providência contra os riscos maiores, construindo em planícies de inundação uma vez que as inundações menores comuns são eliminadas. Uma sociedade sujeita regularmente a riscos menores trata esses perigos menores como um limite superior para o tamanho dos riscos, protegendo-se contra as pequenas inundações regulares, mas não contra ocasionais grandes inundações.</p>
      <p>A memória nem sempre é um bom guia para probabilidades no passado, quanto menos no futuro.</p>

      <p class="endlink"><a target="_blank" href="http://lesswrong.com/lw/j5/availability/"></a></p>

      <notes>
        <note>Sarah Lichtenstein et al., “Judged Frequency of Lethal Events,” <em>Journal of Experimental Psychology: Human Learning and Memory</em> 4, no. 6 (1978): 551–578, <span class="doi">doi</span>:<a target="_blank" href="http://dx.doi.org/10.1037/0278-7393.4.6.551">10.1037/0278-7393.4.6.551</a>.</note>
        <note>Barbara Combs and Paul Slovic, “Newspaper Coverage of Causes of Death,” <em>Journalism &amp; Mass Communication Quarterly</em> 56, no. 4 (1979): 837–849, <span class="doi">doi</span>:<a target="_blank" href="http://dx.doi.org/10.1177/107769907905600420">10.1177/107769907905600420</a>.</note>
        <note>Tradução livre de Howard Kunreuther, Robin Hogarth, and Jacqueline Meszaros, “Insurer Ambiguity and Market Failure,” <em>Journal of Risk and Uncertainty</em> 7 (1 1993): 71–87, <span class="doi">doi</span>:<a target="_blank" href="http://dx.doi.org/10.1007/BF01065315">10.1007/BF01065315</a>.</note>
        <note>Ian Burton, Robert W. Kates, and Gilbert F. White, <em>The Environment as Hazard</em>, 1st ed. (New York: Oxford University Press, 1978).</note>
      </notes>

    </article>

    <article id="art-6"><h1>6. Detalhes onerosos</h1>

      <blockquote>
        <p>Detalhes meramente corroborativos, direcionados a dar verossimilhança artística a uma narrativa de outro modo nua e pouco convincente...</p>
        <p class="quote-author">- Pooh-Bah, em <em>The Mikado</em>, de Gilbert e Sullivan <ref>1</ref></p>
      </blockquote>
      <p>A <a target="_blank" href="http://lesswrong.com/lw/ji/conjunction_fallacy/">falácia da conjunção</a> é quando seres humanos julgam que a probabilidade P(A,B) é maior do que a probabilidade P(B), embora seja um teorema que P(A,B) ≤ P(B). Por exemplo, em um experimento em 1981, 68% dos indivíduos classificavam como mais provável que “Reagan dará apoio federal para mães solteiras e reduzirá o apoio federal aos governos locais” do que “Reagan dará apoio federal para mães solteiras.”</p>
      <p><a target="_blank" href="http://lesswrong.com/lw/jj/conjunction_controversy_or_how_they_nail_it_down/">Uma longa série de experimentos inteligentemente concebidos, que eliminou hipóteses alternativas e definiu a interpretação padrão</a>, confirmou que a falácia da conjunção ocorre porque nós “usamos um juízo de representatividade em substituição ao juízo de probabilidade.” Ao adicionar mais detalhes, você pode fazer um resultado parecer <em>mais</em> característico do processo que o gera. Você pode fazer parecer mais plausível que Reagan vai apoiar as mães solteiras, <em>acrescentando</em> a alegação de que Reagan vai <em>também</em> reduzir o apoio aos governos locais. A implausibilidade de uma alegação é compensada pela plausibilidade da outra; eles “chegam numa média.”</p>
      <p>O que significa dizer: adicionar detalhes pode fazer um cenário PARECER MAIS PLAUSÍVEL, embora o evento necessariamente TORNE-SE MENOS PROVÁVEL.</p>
      <p>Se é assim, então, <em>hipoteticamente falando,</em> podemos encontrar futuristas contando histórias futuras exorbitantemente implausíveis e detalhadas, ou achar pessoas engolindo enormes pacotes de alegações infundadas embrulhadas com algumas afirmações aparentemente fortes no centro. Se você é se depara com a falácia da conjunção em uma comparação clara e direta, então talvez você tenha sucesso naquele problema específico ao se corrigir conscientemente. Mas isso é só colocar um band-aid no problema, não resolvê-lo em geral.</p>
      <p>No <a target="_blank" href="http://lesswrong.com/lw/ji/conjunction_fallacy/">experimento de 1982</a> em que analistas profissionais atribuíram probabilidades sistematicamente superiores para “Rússia invade a Polônia, seguido pela suspensão das relações diplomáticas entre os EUA e a URSS” do que para “suspensão das relações diplomáticas entre os EUA e a URSS”, cada grupo experimental foi apresentado a apenas uma proposição <ref>2</ref>. Qual estratégia esses analistas poderiam ter seguido, como um grupo, que teria eliminado a falácia da conjunção, quando nenhum indivíduo sabia diretamente sobre a comparação? Quando nenhum indivíduo sequer sabia que o experimento era <em>sobre</em> a falácia da conjunção? Como eles poderiam ter ido melhor em seus juízos de probabilidade?</p>
      <p>Remendar uma pegadinha como um caso especial não resolve o problema geral. A pegadinha é o sintoma, não a doença.</p>
      <p>O que os analistas poderiam ter feito para evitar a falácia da conjunção, sem ver a comparação direta, nem saber que alguém iria testá-los sobre a falácia da conjunção? Parece-me que eles precisariam observar a palavra “e”. Eles precisam ter cuidado com ela &mdash; não só ter cuidado, mas pular para longe dela. Mesmo sem saber que os pesquisadores depois iriam testá-los especificamente sobre a falácia da conjunção. Eles teriam de observar a conjunção de <em>dois detalhes inteiros</em>, e ficar <em>chocados</em> com a audácia de alguém pedindo-lhes para endossar tal previsão insanamente complicada. E eles seriam obrigados a penalizar <em>substancialmente</em> a probabilidade &mdash; por um fator de quatro, pelo menos, de acordo com os detalhes experimentais.</p>
      <p>Também poderia ter ajudado se os analistas pensassem em possíveis razões pelas quais os EUA e a União Soviética suspenderiam relações diplomáticas. O cenário não é “os Estados Unidos e a União Soviética de repente suspendem relações diplomáticas sem nenhum motivo”, mas “os Estados Unidos e a União Soviética suspendem relações diplomáticas por algum motivo.”</p>
      <p>E os sujeitos que avaliaram “Reagan dará apoio federal para mães solteiras e reduzirá o apoio federal aos governos locais”? Novamente, eles teriam que ficar chocados com a palavra “e”. Além disso, eles precisariam <em>somar</em> absurdidade &mdash; onde a absurdidade é o logaritmo da probabilidade, então você pode somar &mdash; ao invés de tirar a média delas. Eles precisam pensar, “Reagan pode ou não cortar o apoio aos governos locais (1 bit), mas parece muito improvável que ele vai apoiar as mães solteiras (4 bits). Absurdeza <em>total</em>: 5 bits.” Ou talvez, “Reagan não vai apoiar mães solteiras. Um strike, está fora. A outra proposição só deixa ainda pior.”</p>
      <p>Da mesma forma, imagine um dado de seis lados com quatro faces verdes e duas faces vermelhas. Os sujeitos <a target="_blank" href="http://lesswrong.com/lw/ji/conjunction_fallacy/">tinham que apostar</a> se a sequência (1) RGRRR, (2) GRGRRR, ou (3) GRRRRR apareceria em qualquer lugar em vinte lançamentos dos dados <ref>3</ref>. Sessenta e cinco por cento dos indivíduos escolheu GRGRRR, que é estritamente dominada por RGRRR, uma vez que qualquer sequência contendo GRGRRR também contém RGRRR. Como os sujeitos poderiam ter feito melhor? Percebendo a inclusão? Talvez; mas isso é só um band-aid, ele não resolve o problema fundamental. Calculando explicitamente as probabilidades? Isso certamente resolveria o problema fundamental, mas nem sempre é possível calcular uma probabilidade exata.</p>
      <p>Os sujeitos perderam heuristicamente ao pensar: “Ahá! A Sequência 2 tem a maior proporção de verde para vermelho! Eu devia apostar na Sequência 2!” Para vencer heuristicamente, os indivíduos teriam de pensar: “Ahá! A Sequência 1 é <em>curta</em>! Eu deveria apostar na Sequência 1!”</p>
      <p>Eles precisariam sentir um <em>impacto emocional</em> mais forte da Navalha de Occam &mdash; sentir <em>cada</em> detalhe acrescentado como um fardo, mesmo um único lançamento extra dos dados.</p>
      <p>Era uma vez, em que eu estava falando com alguém que tinha sido hipnotizada por um futurista incauto (um daqueles que acrescenta muitos detalhes que soam bonitos). Eu estava tentando explicar por que eu não estava igualmente fascinado por essas teorias incríveis, inacreditáveis. Então eu expliquei sobre a falácia da conjunção, especificamente o experimento sobre “suspensão de relações ± invasão da Polônia”. E ele disse, “Ok, mas o que isso tem a ver com-” E eu disse: “É mais provável que os universos se replicam <em>por algum motivo</em>, do que que eles se replicam <em>via buracos negros porque civilizações avançadas fabricam buracos negros porque universos evoluem para levá-los a fazer isso</em>”. E ele disse, “Oh.”</p>
      <p>Até então, ele não tinha sentido esses detalhes extras como fardos adicionais. Em vez disso, eles eram detalhes corroborativos, emprestando verossimilhança à narrativa. Alguém lhe apresenta um pacote de idéias estranhas, <em>uma</em> das quais é que universos se replicam. Em seguida, eles apresentam suporte <em>para a afirmação de que universos se replicam</em>. Mas isso não apoia o <a target="_blank" href="http://en.wikipedia.org/wiki/Package-deal_fallacy">pacote</a>, embora tudo sera contado como uma história só.</p>
      <p>Você tem que separar os detalhes. Você tem que segurar cada um independentemente, e perguntar: “Como sabemos <em>este</em> detalhe?” Alguém esboça uma imagem da descida da humanidade à guerra nanotecnológica, onde a China se recusa a acatar um acordo internacional de controle, seguido de uma corrida armamentista... Espere um minuto, como é que você sabe que vai ser a China? Isso no seu bolso é uma bola de cristal, ou você só está feliz por ser um futurista? De onde vêm todos esses detalhes? Do onde veio <em>esse</em> detalhe <em>específico</em>?</p>
      <p>Pois está escrito:</p>
      <blockquote>
        <p><em>Se você pode aliviar seu fardo, você deve fazê-lo.</em></p>
        <p><em>Não há palha alguma que não tenha o poder de quebrar suas costas.</em></p>
      </blockquote>

      <p class="endlink"><a target="_blank" href="http://lesswrong.com/lw/jk/burdensome_details/"></a></p>

      <notes>
        <note>William S. Gilbert e Arthur Sullivan, <em>The Mikado</em>, Opera, 1885.</note>
        <note>Tversky and Kahneman, <a href="#art-intro-n-7">“Extensional Versus Intuitive Reasoning”</a>.</note>
        <note>Amos Tversky and Daniel Kahneman, “Judgments of and by Representativeness,” in <em>Judgment Under Uncertainty: Heuristics and Biases</em>, ed. Daniel Kahneman, Paul Slovic, and Amos Tversky (New York: Cambridge University Press, 1982), 84–98.</note>
      </notes>

    </article>

    <article id="art-7"><h1>7. Falácia do planejamento</h1>

      <p>O <a target="_blank" href="http://en.wikipedia.org/wiki/Denver_International_Airport">Aeroporto Internacional de Denver</a> abriu com 16 meses de atraso, superando os custos previstos em US$2 bilhões. (Eu também já vi alegações de que o excesso teria sido de US$3.1 bilhões.) O <a target="_blank" href="http://en.wikipedia.org/wiki/Eurofighter">Eurofighter Typhoon</a>, um projeto conjunto de defesa de vários países europeus, foi entregue com um atraso de 54 meses, a um custo de US$19 milhões, ao invés de US$7 bilhões. O <a target="_blank" href="http://en.wikipedia.org/wiki/Sydney_opera_house">Sydney Opera House</a> pode ser a construção com o custo excedente mais lendário de todos os tempos, originalmente previsto para ser concluído em 1963 por US$7 milhões e, finalmente, concluído em 1973 por US$102 milhões <ref>1</ref>.</p>
      <p>Estes desastres isolados são trazidos à nossa atenção por <a href="#art-5" title="Disponibilidade">disponibilidade</a> seletiva? Eles são sintomas de falhas na burocracia ou nos incentivos do governo? Sim, muito provavelmente. Mas há também um viés cognitivo correspondente, replicado em experimentos com planejadores individuais.</p>
      <p>Buehler et al. pediram a seus alunos estimativas de quando eles (os alunos) acreditavam que completariam seus projetos acadêmicos pessoais <ref>2</ref>. Especificamente, os pesquisadores pediram estimativas de tempo em que os alunos achavam que era 50%, 75% e 99% provável que seus projetos pessoais estivessem completos. Você quer tentar adivinhar quantos estudantes terminaram dentro dos prazos que eles estimaram para 50%, 75% e 99% de probabilidade?</p>
      <ul>
        <li> 13% dos sujeitos terminaram seus projetos dentro do prazo a que eles tinham atribuído um nível de probabilidade de 50%;</li>
        <li> 19% terminaram dentro de seu prazo de nível de probabilidade de 75%;</li>
        <li> e só 45% (menos da metade!) terminaram dentro do prazo de seu nível de probabilidade de 99%.</li>
      </ul>
      <p>Como Buehler et al. escreveram: “Os resultados para o nível de probabilidade de 99% são especialmente impressionantes: mesmo quando solicitados a fazer uma previsão altamente conservadora, uma previsão em que se sentissem praticamente certos de que iriam cumprir, a confiança dos estudantes em suas estimativas de tempo superou em muito as suas realizações.” <ref>3</ref>.</p>
      <p>De modo mais geral, este fenômeno é conhecido como a “falácia do planejamento”. A falácia de planejamento é que as pessoas acham que conseguem planejar, haha.</p>
      <p>Uma pista para o problema subjacente ao algoritmo de planejamento foi descoberto por Newby-Clark et al., que descobriu que</p>
      <ul>
        <li> Pedir aos sujeitos suas previsões com base em cenários realistas de sua “melhor estimativa”; e</li>
        <li> Pedir aos sujeitos sobre seus cenários para o “melhor caso possível”...</li>
      </ul>
      <p>...produzia resultados <em>indistinguíveis</em> <ref>4</ref>.</p>
      <p>Quando se pede às pessoas que pensem num cenário “realista”, elas imaginam tudo acontecendo exatamente como planejado, sem atrasos <em>inesperados</em> ou catástrofes <em>imprevistas</em> &mdash; a mesma visão que o seu “melhor caso possível”.</p>
      <p>A realidade, verifica-se, geralmente produz resultados um pouco piores do que o “pior caso”.</p>
      <p>Diferentemente da maioria dos vieses cognitivos, sabemos de uma boa heurística de correção para a falácia de planejamento. Não vai funcionar para bagunças na escala do Aeroporto Internacional de Denver, mas vai funcionar para boa parte do seu planejamento pessoal, e até mesmo para algumas questões organizacionais em pequena escala. Basta usar uma “visão exterior”, ao invés de uma “visão interior”.</p>
      <p>As pessoas tendem a gerar as suas previsões pensando sobre as características específicas, únicas da tarefa em mãos, e construindo um cenário de como pretendem concluir a tarefa &mdash; o que é exatamente o que nós geralmente chamamos de <em>planejamento.</em> Quando você quer fazer alguma coisa, você tem que planejar onde, quando, como; descobrir quanto tempo e quantos recursos são necessários; visualizar as etapas do início à conclusão bem sucedida. Tudo isso é a “visão interior”, e não leva em conta os atrasos inesperados e catástrofes imprevistas. Como vimos antes, pedir às pessoas para visualizar o “pior caso” ainda não é suficiente para neutralizar seu otimismo &mdash; eles não imaginam “Murphyneza” suficiente.</p>
      <p>A visão exterior é quando você deliberadamente <em>evita</em> pensar sobre as características especiais, únicas desse projeto, e só pergunta quanto tempo demorou para concluir projetos, <em>em linhas gerais</em>, semelhantes no passado. Isso é contraintuitivo, uma vez que a visão de dentro tem muito mais detalhes &mdash; há uma tentação de pensar que uma previsão cuidadosamente adaptada, levando em conta todos os dados disponíveis, dará melhores resultados.</p>
      <p>Mas o experimento mostrou que quanto mais detalhada é a visão dos sujeitos, mais otimistas (e menos precisas) elas se tornam. Buehler et al. pediu a um grupo experimental de indivíduos que descrevessem planos muito específicos para suas compras de Natal &mdash; onde, quando e como <ref>5</ref>. Em média, este grupo esperava terminar as compras mais de uma semana antes do Natal. Para outro grupo, apenas se perguntou quando esperavam concluir suas compras de Natal, e a resposta média foi de quatro dias de antecedência. Ambos os grupos terminaram, em média, três dias antes do Natal.</p>
      <p>Da mesma forma, Buehler et al., relatando um estudo transcultural, descobriu que estudantes japoneses previam terminar de escrever seus ensaios 10 dias antes do prazo final. Eles, na verdade, terminaram um dia antes do fim do prazo. Questionados sobre quando eles haviam concluído tarefas semelhantes no passado, eles responderam: “um dia antes do fim do prazo” <ref>6</ref>. Este é o poder da visão exterior sobre a visão interior.</p>
      <p>Uma conclusão semelhante é que observadores externos experientes, que sabem menos dos detalhes, mas que têm memórias relevantes em que se basear, muitas vezes são muito menos otimistas e muito mais precisos do que os verdadeiros planejadores e executores.</p>
      <p>Portanto, há uma maneira bastante confiável de corrigir a falácia de planejamento, se você está fazendo algo <em>em linhas gerais</em> similar a uma classe de projetos anteriores de referência. Basta perguntar quanto tempo projetos semelhantes tomaram no passado, sem considerar <em>qualquer</em> das propriedades especiais deste projeto. Melhor ainda, perguntar a um observador externo experiente quanto tempo projetos semelhantes levaram.</p>
      <p>Você receberá de volta uma resposta que soa terrivelmente longa, e claramente demonstra total falta de compreensão das razões especiais pelas quais essa tarefa em particular levará menos tempo. Esta resposta é verdadeira. Lide com ela.</p>

      <p class="endlink"><a target="_blank" href="http://lesswrong.com/lw/jg/planning_fallacy/"></a></p>

      <notes>
        <note>Roger Buehler, Dale Griffin, e Michael Ross, “Inside the Planning Fallacy: The Causes and Consequences of Optimistic Time Predictions,” em Gilovich, Griffin, e Kahneman, <a href="#art-intro-n-23"><em>Heuristics and Biases</em></a>, 250-270.</note>
        <note>Roger Buehler, Dale Griffin, and Michael Ross, “Exploring the ‘Planning Fallacy’: Why People Underestimate Their Task Completion Times,” <em>Journal of Personality and Social Psychology</em> 67, no. 3 (1994): 366–381, <span class="doi">doi</span>:<a target="_blank" href="http://dx.doi.org/10.1037/0022-3514.67.3.366">10.1037/0022-3514.67.3.366</a>;  Roger Buehler, Dale Griffin, and Michael Ross, “It’s About Time: Optimistic Predictions in Work and Love,” <em>European Review of Social Psychology</em> 6, no. 1 (1995): 1–32, <span class="doi">doi</span>:<a target="_blank" href="http://dx.doi.org/10.1080/14792779343000112">10.1080/14792779343000112</a>.</note>
        <note>Buehler, Griffin, and Ross, <a href="#Notas_de_Rodap.C3.A9">“Inside the Planning Fallacy”</a>.</note>
        <note>Ian R. Newby-Clark et al., “People Focus on Optimistic Scenarios and Disregard Pessimistic Scenarios While Predicting Task Completion Times,” <em>Journal of Experimental Psychology: Applied</em> 6, no. 3 (2000): 171–182, <span class="doi">doi</span>:<a target="_blank" href="http://dx.doi.org/10.1037/1076-898X.6.3.171">10.1037/1076-898X.6.3.171</a>.</note>
        <note>Buehler, Griffin, and Ross, <a href="#Notas_de_Rodap.C3.A9">“Inside the Planning Fallacy”</a>.</note>
        <note><a href="#Notas_de_Rodap.C3.A9">Ibid</a>.</note>
      </notes>

    </article>

    <article id="art-8"><h1>8. Ilusão de transparência: por que ninguém entende você</h1>

      <p>Por causa do <a target="_blank" href="http://lesswrong.com/lw/il/hindsight_bias/">viés de retrospectiva</a>, as pessoas que sabem o resultado de uma situação acreditam que teria sido fácil prevê-lo com antecedência. Sabendo o resultado, nós <a target="_blank" href="http://racionalidade.com.br/wiki/Fake_Causality" title="Fake Causality">reinterpretamos a situação</a> à luz dele. Mesmo quando avisados, não conseguimos desinterpretar para entender o que se passa na cabeça de alguém que não sabe o que sabemos.</p>
      <p>Intimamente relacionada a isso é a <em>ilusão de transparência</em>: Nós sempre sabemos o que <em>nós</em> queremos dizer com nossas palavras, e, assim, esperamos que os outros saibam também. Lendo nossos próprios escritos, a interpretação pretendida se encaixa facilmente, guiada pelo nosso conhecimento sobre o que realmente queríamos dizer. É difícil entender alguém que precisa interpretar cegamente, guiado apenas pelas palavras.</p>
      <p>June recomenda um restaurante a Mark; Mark janta lá e encontra (a) uma comida nada impressionante e serviço medíocre ou (b) comida deliciosa e serviço impecável. Então Mark deixa a seguinte mensagem na secretária eletrônica de June: “June, acabei de jantar no restaurante que você recomendou, e devo dizer que foi maravilhoso, simplesmente maravilhoso”. Keysar apresentou a um grupo de indivíduos o cenário (a), e 59% acharam que a mensagem de Mark fora sarcástica <em>e que Jane iria perceber o sarcasmo</em>.<ref>1</ref> Entre outros sujeitos, aos quais foi apresentado o cenário (b), apenas 3% achavam que Jane iria entender a mensagem de Mark como sarcástica. No seu artigo, Keysar e Barr parecem indicar que uma mensagem de voz real foi reproduzida para os indivíduos.<ref>2</ref> Keysar mostrou que, se os indivíduos fossem informados de que o restaurante era horrível, <em>mas que Mark queria esconder sua impressão</em>, eles acreditavam que June não perceberia sarcasmo na (mesma) mensagem:<ref>3</ref></p>
      <blockquote>Eles tinham a mesma probabilidade de achar que ela iria perceber o sarcasmo se ele tentasse esconder sua experiência negativa do que se ele tivesse uma experiência positiva e fosse realmente sincero. Ou seja, os participantes tomaram a <em>intenção comunicativa</em> de Mark como transparente. Era como se eles presumissem que June entenderia a intenção que Mark queria que ela entendesse, qualquer que ela fosse.<ref>4</ref></blockquote>
      <p>“The goose hangs high” <em>[“O ganso está no alto”]</em> é uma expressão do Inglês arcaico que saiu de uso na língua moderna. Keysar e Bly disseram a um grupo de indivíduos que “the goose hangs high” significava que o futuro parece promissor; outro grupo de sujeitos aprendeu que “the goose hangs high” significava que o futuro parece sombrio.<ref>5</ref> Os indivíduos foram então questionados sobre qual destes dois significados um ouvinte <em>desinformado</em> estaria mais propenso a atribuir à expressão. Cada grupo pensou que os ouvintes considerariam o significado que lhes fora ensinado no experimento como sendo o convencional.</p>
      <p>(Outras expressões testadas incluem “come the uncle over someone”, “to go by the board” e “to lay out in lavender”. Ah, o Inglês, uma língua tão adorável.)</p>
      <p>Keysar e Henly testaram a calibração de oradores:<ref>6</ref> os oradores iriam subestimar, superestimar ou estimar corretamente a frequência com que seus ouvintes compreenderiam o que eles queriam dizer? Oradores receberam frases ambíguas (“O homem está perseguindo uma mulher em uma bicicleta.”) e imagens que resolviam a ambiguidade (um homem correndo atrás de uma mulher, a qual estava andando de bicicleta), em seguida, lhes foi solicitado que proferissem as palavras na frente de ouvintes, e, então, tiveram que estimar quantos ouvintes haviam entendido o significado pretendido. Os oradores acreditavam que eram compreendidos em 72% dos casos, mas, na verdade, eram compreendidos em 61% dos casos. Quando os ouvintes não entendiam a mensagem, os oradores achavam que eles tinham entendido em 46% dos casos; quando os ouvintes entendiam, os oradores achavam que não tinham sido compreendidos em apenas 12% dos casos.</p>
      <p>Outros sujeitos que apenas <em>escutaram</em> a fala sendo dita não mostraram esse viés, esperando que os ouvintes compreendessem a mensagem em apenas 56% dos casos.</p>
      <p>Como Keysar e Barr notam, dois dias antes do ataque da Alemanha à Polônia, Chamberlain enviou uma carta pretendendo deixar claro que a Grã-Bretanha iria à luta se houvesse qualquer invasão.<ref>7</ref> A carta, redigida em diplomatês polido, foi entendida por Hitler como conciliadora &mdash; e os tanques avançaram.</p>
      <p>Não seja rápido demais para culpar aqueles que não compreendem suas frases perfeitamente claras, faladas ou escritas. Há boas chances de que suas palavras sejam mais ambíguas do que você imagina.</p>

      <p class="endlink"><a target="_blank" href="http://lesswrong.com/lw/ke/illusion_of_transparency_why_no_one_understands/"></a></p>

      <notes>
        <note>Boaz Keysar, “The Illusory Transparency of Intention: Linguistic Perspective Taking in Text,” <em>Cognitive Psychology</em> 26 (2 1994): 165–208, <span class="doi">doi</span>:<a target="_blank" href="http://dx.doi.org/10.1006/cogp.1994.1006">10.1006/cogp.1994.1006</a>.</note>
        <note>Keysar and Barr, “<a href="#art-intro-n-23">Self-Anchoring in Conversation</a>.”</note>
        <note>Boaz Keysar, “Language Users as Problem Solvers: Just What Ambiguity Problem Do They Solve?,” in <em>Social and Cognitive Approaches to Interpersonal Communication</em>, ed. Susan R. Fussell and Roger J. Kreuz (Mahwah, NJ: Lawrence Erlbaum Associates, 1998), 175–200.</note>
        <note>Keysar and Barr, “<a href="#art-intro-n-23">Self-Anchoring in Conversation</a>”.</note>
        <note>Boaz Keysar and Bridget Bly, “Intuitions of the Transparency of Idioms: Can One Keep a Secret by Spilling the Beans?,” <em>Journal of Memory and Language</em> 34 (1 1995): 89–109, <span class="doi">doi</span>:<a target="_blank" href="http://dx.doi.org/10.1006/jmla.1995.1005">10.1006/jmla.1995.1005</a>.</note>
        <note>Boaz Keysar and Anne S. Henly, “Speakers’ Overestimation of Their Effectiveness,” <em>Psychological Science</em> 13 (3 2002): 207–212, <span class="doi">doi</span>:<a target="_blank" href="http://dx.doi.org/10.1111/1467-9280.00439">10.1111/1467-9280.00439</a>.</note>
        <note>Keysar and Barr, “<a href="#art-intro-n-23">Self-Anchoring in Conversation</a>.”</note>
      </notes>

    </article>

    <article id="art-9"><h1>9. Esperando distâncias inferenciais curtas</h1>

      <p>O <a target="_blank" href="http://en.wikipedia.org/wiki/Evolutionary_psychology#Environment_of_evolutionary_adaptedness">ambiente de adaptação evolutiva</a> do <em>Homo sapiens</em> (também conhecido como AAE ou “ambiente ancestral”) consistia de  <a target="_blank" href="http://en.wikipedia.org/wiki/Band_society">bandos</a> de caçadores-coletores de no máximo <a target="_blank" href="http://en.wikipedia.org/wiki/Dunbar%27s_number">200 pessoas</a>, sem escrita. Todo o conhecimento herdado era transmitido pela fala e memória.</p>
      <p>Em um mundo como esse, todo o conhecimento prévio é conhecimento universal. Todas as informações não estritamente privadas são públicas, ponto final.</p>
      <p>No ambiente ancestral, era improvável você acabar ficando mais do que <em>um passo inferencial</em> além de qualquer outra pessoa. Quando você descobre um novo oásis, você não tem que explicar aos seus colegas membros da tribo que é um oásis, ou porque é uma boa idéia beber água, ou como andar. Só você sabe onde fica o oásis; isso é conhecimento privado. Mas todo mundo tem os pressupostos para compreender a sua descrição do oásis, os conceitos necessários para pensar sobre a água; isso é conhecimento universal. Ao explicar as coisas no ambiente ancestral, você quase <em>nunca</em> tinha que explicar seus conceitos. No máximo, você teria que explicar <em>um</em> novo conceito, e não dois ou mais simultaneamente.</p>
      <p>No ambiente ancestral não havia disciplinas abstratas com grandes corpos de evidências cuidadosamente coletadas generalizadas em teorias elegantes transmitidas por livros escritos cujas conclusões estão <em>a uma centena de passos inferenciais de distância</em> das premissas universalmente compartilhadas.</p>
      <p>No ambiente ancestral, qualquer um que dissesse algo sem suporte óbvio seria um mentiroso ou um idiota. Não era provável que você pensasse: “Ei, talvez essa pessoa tenha conhecimentos prévios bem fundamentados que ninguém na minha banda sequer ouviu falar”, porque era uma invariante confiável do ambiente ancestral que isso não acontecia.</p>
      <p>E para finalizar, se alguém dissesse algo sem suporte óbvio, <em>esperando</em> que você acreditasse &mdash; agindo todo indignado quando você não o fizesse, então eles deveriam estar <em>loucos.</em></p>
      <p>Combinado com <a href="#art-8" title="Ilusão de transparência: Por que ninguém entende você">a ilusão de transparência</a> e <a target="_blank" href="http://lesswrong.com/lw/kf/selfanchoring/">auto-ancoragem</a>, eu acho que isso explica <em>muito</em> sobre a dificuldade lendária que a maioria dos cientistas têm em se comunicar com um público leigo &mdash; ou mesmo em se comunicar com cientistas de outras disciplinas. Quando observo falhas de explicação, eu costumo ver o explicador tomar <em>um</em> passo para trás, quando eles precisam tomar dois ou mais passos para trás. Ou ouvintes pressupõem que as coisas deveriam ser visíveis em um único passo, quando eles levam dois ou mais passos para se explicar. Ambos os lados agem como se esperassem distâncias inferenciais muito curtas a partir do conhecimento universal até qualquer novo conhecimento.</p>
      <p>Um biólogo, falando com um físico, pode justificar a evolução dizendo que é a explicação mais simples. Mas nem todo mundo na Terra foi inculcada com  a lendária história da ciência, de Newton a Einstein, que dà a frase “explicação mais simples” sua importância impressionante: uma Palavra de Poder, falada no nascimento de teorias e esculpida em suas lápides. Para outra pessoa, “Mas é a explicação mais simples!” pode soar como um argumento interessante, mas dificilmente fulminante; ele não parece uma ferramenta tão poderosa para compreender a política do escritório ou consertar um carro quebrado. Obviamente, o biólogo está apaixonado por suas próprias idéias, arrogante demais para estar aberto a explicações alternativas que soam igulmente plausíveis. (Se isso soa plausível para mim, deve soar plausível para qualquer membro são do meu bando.)</p>
      <p>E da perspectiva do biólogo, ele consegue entender como a evolução pode soar um pouco estranha no começo &mdash; mas quando alguém rejeita a evolução mesmo após o biólogo explicar que é a explicação mais simples, bem, é claro que não-cientistas são apenas idiotas e não adianta nada falar a eles.</p>
      <p>Um argumento claro tem que apresentar um “caminho” inferencial, partindo daquilo que a audiência <em>já sabe ou aceita.</em> Se você não der passos para trás o suficiente, você estará falando apenas para si mesmo.</p>
      <p>Se em algum momento você fizer uma afirmação sem justificativa óbvia nos argumentos que você sustentou antes, a audiência simplesmente vai achar que você é louco.</p>
      <p>Isso também acontece quando você se permite ser visto dando <em>visivelmente</em> mais peso a um argumento do que a audiência considera justificado <em>naquele momento</em>. Por exemplo, falar como se você pensasse que “explicação mais simples” é um argumento fulminante a favor da evolução (o que ele é), ao invés de uma idéia um pouco interessante (o que ele parece que para alguém que não tenha sido criado para reverenciar a Navalha de Occam).</p>
      <p>Ah, e é melhor você não dar nenhuma dica de que <em>você</em> acha que está trabalhando a uma dúzia de passos inferenciais de distância do que a audiência conhece, ou de que <em>você</em> acha que tem conhecimento prévio especial que não está disponível para eles. O público não sabe nada sobre um argumento evolutivo-picológico a respeito de um viés cognitivo de subestimar distâncias inferenciais levando a congestionamentos na comunicação. Eles só vão pensar que você está sendo condescendente.</p>
      <p>E se você acha que consegue explicar o conceito de “distâncias inferenciais sistematicamente subestimadas” brevemente, em poucas palavras, eu tenho uma notícia triste para você...</p>

      <p class="endlink"><a target="_blank" href="http://lesswrong.com/lw/kg/expecting_short_inferential_distances/"></a></p>

    </article>

    <article id="art-10"><h1>10. A lente que vê suas próprias falhas</h1>

      <p>A luz deixa o Sol e atinge o seu cadarço e é refletida; alguns fótons penetram a pupila dos seus olhos e atingem sua retina; a energia dos fótons dispara impulsos nervosos; os impulsos nervosos são transmitidos às áreas de processamento visual do cérebro; e ali a informação ótica é processada e reconstruída num modelo 3D que é reconhecido como um cadarço desamarrado; e assim você acredita que seu cadarço está desamarrado.</p>
      <p>Eis o segredo da <em>racionalidade deliberada</em>—todo esse processo de entrelaçamento não é <a target="_blank" href="http://racionalidade.com.br/wiki/Mysterious_Answers_to_Mysterious_Questions" title="Mysterious Answers to Mysterious Questions">mágico</a>, e você pode <em>entendê-lo</em>. Você pode <em>entender</em> de que maneira enxerga seu cadarço. Você pode <em>pensar</em> sobre que tipo de processos de pensamento criará crenças que refletem a realidade, e quais processos de pensamento não o farão.</p>
      <p>Ratos podem ver, mas eles não conseguem entender o fenômeno em si da visão. <em>Você</em> consegue entendê-lo e, por causa disso, você pode fazer coisas que os ratos não podem. Tome um momento para <a target="_blank" href="http://racionalidade.com.br/wiki/%22Science%22_as_Curiosity-Stopper" title="&quot;Science&quot; as Curiosity-Stopper" class="mw-redirect">admirar</a> esse fato, pois é realmente admirável.</p>
      <p>Ratos enxergam, mas eles não sabem que têm córtices visuais, de modo que não conseguem corrigir ilusões de ótica. Um rato vive num mundo mental que inclui gatos, buracos, queijo e ratoeiras—mas não cérebros de rato. A câmera deles não tira fotos de sua própria lente. Mas nós, seres humanos, podemos olhar uma <a target="_blank" href="http://www.richrock.com/gifs/optical-illusion-wheels-circles-rotating.png">imagem aparentemente bizarra</a> e perceber que parte do que nós estamos vendo é a própria lente. Você nem sempre tem que acreditar em seus próprios olhos, mas tem que perceber que você <em>possui</em> olhos—você deve ter baldes mentais distintos para o mapa e o território, para os sentidos e para a realidade. Para que você não ache que essa seja uma capacidade trivial, lembre-se de como é rara no reino animal.</p>
      <p>Toda a Ciência se resume, simplesmente, no raciocínio reflexivo sobre processos mais confiáveis para fazer o conteúdo da sua mente refletir o conteúdo do mundo. É o tipo de coisa que ratos nunca inventariam. Ponderando essa prática de “realizar experimentos replicáveis ​​para falsear teorias”, conseguimos ver <em>por que</em> isso funciona. A ciência não é um <a target="_blank" href="http://racionalidade.com.br/wiki/Religion%27s_Claim_to_be_Non-Disprovable" title="Religion's Claim to be Non-Disprovable">magistério separado</a>, longe da vida real e da compreensão de meros mortais. A ciência não é algo que só se aplica ao <a target="_blank" href="http://racionalidade.com.br/wiki/Outside_the_Laboratory" title="Outside the Laboratory">interior dos laboratórios</a>. A ciência, em si, é um processo-no-mundo compreensível que correlaciona cérebros com a realidade.</p>
      <p>A Ciência <em>faz sentido</em>, se você parar pra pensar. Mas ratos não conseguem pensar sobre o pensar, razão pela qual eles não têm Ciência. Não se deve fechar os olhos para tal maravilha—ou para o poder potencial que isso concede a nós enquanto indivíduos, não apenas a sociedades científicas.</p>
      <p>É bem verdade que a compreensão do mecanismo do pensamento pode ser <em>um pouco mais complicada</em> do que a compreensão de um motor a vapor — mas não é uma tarefa <em>fundamentalmente</em> diferente.</p>
      <p>Algum tempo atrás, fui à sala de bate-papo #philosophy da EFNet para perguntar: “Você acredita que uma guerra nuclear ocorrerá nos próximos 20 anos? Se não, por que não?” Um dos que responderam disse que não esperava uma guerra nuclear por pelo menos 100 anos, porque “Todos os atores envolvidos em decisões sobre guerra nuclear não estão interessados no momento.” “Mas por que estender por 100 anos?”, perguntei. “Pura esperança”, foi sua resposta.</p>
      <p>Ao refletir sobre todo esse processo de pensamento, podemos entender por que a ideia de guerra nuclear deixa essa pessoa infeliz, e podemos entender como o cérebro dele consequentemente rejeita essa crença. Mas, se você imaginar um bilhão de mundos—ramos de Everett, ou <a target="_blank" href="http://arxiv.org/abs/astro-ph/0302131">duplicatas de Tegmark</a><ref>1</ref> — esse processo de pensamento não <a target="_blank" href="http://racionalidade.com.br/wiki/What_Is_Evidence%3F" title="What Is Evidence?">correlacionará sistematicamente</a> otimistas com ramos onde não ocorre guerra nuclear. (Algum sujeito esperto dirá: “Ah, mas uma vez que tenho esperança, vou trabalhar um pouco mais no meu emprego, aquecer a economia global, e assim ajudar a impedir os países de cair num estado de raiva e desesperança, onde a guerra nuclear é uma possibilidade. Então os dois eventos estão relacionados, afinal de contas.” A esta altura, temos de nos reportar ao <a target="_blank" href="http://racionalidade.com.br/wiki/Interlude:_An_Intuitive_Explanation_of_Bayes%27s_Theorem" title="Interlude: An Intuitive Explanation of Bayes's Theorem">Teorema de Bayes</a> e medir a carga de entrelaçamento quantitativamente. Sua natureza otimista não pode ter um efeito <em>a tal ponto</em> grande sobre o mundo; ela não pode, por si só, diminuir de 20% a probabilidade de guerra nuclear, ou de quanto for que sua natureza otimista mudou suas crenças. Mudar suas crenças em um grau alto, devido a um evento que só aumenta ligeiramente a chance de você estar certo, também vai atrapalhar o seu mapeamento.)</p>
      <p>Perguntar quais crenças fazem você feliz é se voltar para dentro, não para fora — isso lhe diz algo sobre si mesmo, mas não é uma evidência entrelaçada com o ambiente. Não tenho nada, qualquer coisa, contra a felicidade, mas ela deveria <a href="#art-2" title="Sentindo-se racional">emergir da</a> sua imagem do mundo, em vez de mexer indevidamente com os pincéis mentais.</p>
      <p>Se você consegue visualizar isso — se você pode ver que a esperança está mudando demasiadamente seus pensamentos de <em>primeira ordem</em> — se você entende sua mente como um mecanismo de mapeamento com falhas — então você pode aplicar uma correção reflexiva. O cérebro é uma lente falha através da qual se enxerga a realidade. Isto é verdade para os cérebros tanto de camundongos quanto de humanos. Mas o cérebro humano é uma lente falha que pode compreender suas próprias falhas — seus erros sistemáticos, seus vieses — e lhes aplicar correções de segunda ordem. Isto, <em>na prática</em>, torna a lente muito mais poderosa. Não perfeita, mas muito mais poderosa.</p>

      <p class="endlink"><a target="_blank" href="http://lesswrong.com/lw/jm/the_lens_that_sees_its_flaws/"></a></p>

      <notes>
        <note>Max Tegmark, “Parallel Universes”, em <em>Science and Ultimate Reality: Quantum Theory, Cosmology, and Complexity</em>, ed. John D. Barrow, Paul Davies CW, e Charles L. Harper Jr. (New York: Cambridge University Press, 2004), 459-491.</note>
      </notes>

    </article>

  </section>

</section>

</body>

</html>
